---
layout: post
title: "ðŸ’¡ TIL: TF-IDF vs BM25"
date: 2024-11-20
tags: [til, tf-idf, bm25, text-ranking, nlp]
toc: true
---

**TL;DR:** While TF-IDF ranks documents based on term frequency weighted by rarity across a corpus, BM25 improves upon this foundation by adding term frequency saturation and document length normalisation. Choose TF-IDF for simpler tasks with uniformly-sized documents, but prefer BM25 for search engines handling varied document lengths where its sophisticated algorithm delivers superior retrieval performance despite requiring more complex implementation and parameter tuning.

<!--more-->

## Introduction
When building search engines or document retrieval systems, two algorithms often come up: [TF-IDF](https://en.wikipedia.org/wiki/Tf%E2%80%93idf) and [Okapi BM25](https://en.wikipedia.org/wiki/Okapi_BM25). While both aim to rank documents by relevance, they differ significantly in their approach and effectiveness. Today, I learned the key differences between these techniques and when to use each one.

## TF-IDF: The Classic Approach
TF-IDF (Term Frequency-Inverse Document Frequency) ranks documents based on how frequently terms appear in a document, weighted by how rare those terms are across all documents. It's straightforward: if a word appears often in a document but is rare across the corpus, it's probably important[^1]. $idf$ is calculated as follows:  

$$idf(t) = \log\frac{N}{n_t}$$  

where:    
$N$ : Total number of documents in corpus  
$n_t$ : Number of documents containing term $t$  

TF-IDF is derived by the following calculation:  

$$TF\text{-}IDF(t,d) = tf(t,d) \cdot idf(t)$$  

where:    
$tf(t,d)$ : Frequency of term $t$ in document $d$  

### Advantages
- Simple to understand and implement
- Computationally efficient
- Works well for documents of similar length
- Great for basic document classification

### Disadvantages
- No term frequency saturation (more occurrences always mean higher scores)
- Doesn't handle varying document lengths well
- Can overemphasise common terms in long documents

## BM25: The Modern Evolution
BM25 (Best Match 25) builds upon TF-IDF's foundation but adds two crucial improvements: term frequency saturation and document length normalisation. Note how the $idf_{BM25}$ component differs from TF-IDF's:  

$$idf_{BM25}(t) = \log\frac{N - n_t + 0.5}{n_t + 0.5}$$

This modification provides smoother IDF weights and better handles edge cases.

$$BM25(t,d) = \frac{tf(t,d) \cdot (k_1 + 1)}{tf(t,d) + k_1 \cdot (1 - b + b \cdot \frac{|d|}{avgdl})} \cdot idf_{BM25}$$

where:    
$tf(t,d)$ : Frequency of term $t$ in document $d$  
$\|d\|$ : Length of document $d$ (in words)  
$avgdl$ : Average document length in corpus  
$k_1$ : Term frequency saturation parameter (typically 1.2-2.0)  
$b$ : Length normalisation parameter (typically 0.75)  
$N$ : Total number of documents in corpus  
$n_t$ : Number of documents containing term $t$  

### Advantages
- Better handles varying document lengths
- Prevents term frequency from dominating scores
- More nuanced relevance rankings
- Industry standard for search engines

### Disadvantages
- More complex implementation
- Requires parameter tuning
- Slightly higher computational cost
- Less interpretable than TF-IDF

## Which to Choose?

### Choose TF-IDF when:
- Building basic document classification systems
- Working with uniformly-sized documents
- Needing interpretable results
- Prioritising implementation simplicity

### Choose BM25 when:
- Building a search engine
- Handling documents of varying lengths
- Requiring state-of-the-art retrieval performance
- Working with user queries

## Conclusion
While TF-IDF remains valuable for simpler tasks and educational purposes, BM25 is generally superior for serious search applications. The choice between them often comes down to the trade-off between simplicity and sophistication. For modern search engines, BM25 is the clear winner, but TF-IDF's simplicity makes it perfect for learning and basic applications.

Remember: the best algorithm is the one that meets your specific needs. Don't automatically reach for BM25 just because it's more advanced â€“ sometimes, simpler is better.

[^1]: This is why TF-IDF is effective at identifying characteristic terms in documents. It automatically downweights common words like "the", "and", "is" while highlighting distinctive terms that appear frequently in specific documents.
