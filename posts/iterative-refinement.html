<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>üîÑ Considering Iterative Refinement Over Unit Testing - Just-in-Time Learning</title>
  <link rel="stylesheet" href="/style.css">
</head>
<body>
  <header>
    <div class="container">
      <h1>Just-in-Time Learning</h1>
      <p class="subtitle">Inquisitive. Learning. Sharing. Simplicity = Reliability</p>
      <nav>
        <a href="/" class="back-link">‚Üê Back to Home</a>
      </nav>
    </div>
  </header>

  <main class="post-container">
    <article class="post">
      <header class="post-header">
        <h1>üîÑ Considering Iterative Refinement Over Unit Testing</h1>
        <span class="post-date">November 22, 2024</span>
        <div class="post-tags">
          <span class="post-tag">fast-ai</span><span class="post-tag">answer-ai</span><span class="post-tag">iterative-refinement</span><span class="post-tag">doctests</span><span class="post-tag">best-practices</span><span class="post-tag">llm</span><span class="post-tag">dialogue-engineering</span><span class="post-tag">code-quality</span>
        </div>
      </header>
      
      <div class="post-content">
        <p>
<strong>TL;DR:</strong> Drawing inspiration from Norvig, Howard, and Sanderson, this article advocates for iterative refinement over traditional unit testing, emphasising techniques like doctests that keep verification close to code-reducing maintenance burden whilst improving reliability by focusing on actual usage patterns rather than rigid test-driven development that can lead to outdated tests and ossified code structures.</p>
<!--more-->
<h2>
Introduction</h2>
<p>
In the realm of software development and related fields, three influential figures -Peter Norvig (former Director of Research at Google), Jeremy Howard (founder of fast.ai), and Grant Sanderson (creator of 3Blue1Brown)- demonstrate the power of iterative refinement over rigid test-driven development. Their approaches, while applied in different domains, share common principles that challenge traditional development practices.</p>
<h2>
Iterative Refinement</h2>
<h3>
Peter Norvig‚Äôs Software Development</h3>
<p>
Norvig‚Äôs approach, demonstrated in both his <a href="https://norvig.com/docex.html">original <code class="inline">docex</code> module</a> and his <a href="https://norvig.com/spell-correct.html">spell corrector implementation</a>, emphasises tests that are tightly coupled with the code they verify. Before Python‚Äôs doctests[^1] were officially supported, he created the <code class="inline">docex</code> module specifically to write tests in docstrings using a concise syntax like</p>
<pre><code class="python">def factorial(n):
    &quot;&quot;&quot;Return the factorial of n, an exact integer &gt;= 0.
       &gt;&gt;&gt; [factorial(n) for n in range(6)]
       [1, 1, 2, 6, 24, 120]
       It must also not be ridiculously large:
       &gt;&gt;&gt; factorial(1e100)
       Traceback (most recent call last):
       ...
       OverflowError: n too large
    &quot;&quot;&quot;
    ...

if __name__ == &quot;__main__&quot;:
    import doctest
    doctest.testmod()</code></pre>
<pre><code class="console">$ python fact.py -v
Trying:
    [factorial(n) for n in range(6)]
Expecting:
    [1, 1, 2, 6, 24, 120]
ok
Trying:
    factorial(1e100)
Expecting:
    Traceback (most recent call last):
        ...
    OverflowError: n too large
ok
2 items passed all tests:
   1 test in __main__
   6 tests in __main__.factorial
7 tests in 2 items.
7 passed.
Test passed.
$</code></pre>
<p>
Even in his spell corrector, Norvig uses simple functions with in-line test cases rather than separate test files. This approach keeps tests close to the code they verify, making them part of the living documentation rather than separate artefacts that can drift out of sync.\ <em>Update: While randomly skimming through PyTorch code, it was good to stumble across examples of <a href="https://github.com/pytorch/pytorch/blob/main/torch/autograd/grad_mode.py">code containing doctests</a>.</em></p>
<h3>
Jeremy Howard‚Äôs Machine Learning Development</h3>
<p>
Howard‚Äôs methodology, evidenced in fast.ai‚Äôs development and his book ‚ÄúDeep Learning for Coders‚Äù advocates for rapid prototyping in notebooks. His emphasis lies in getting end-to-end solutions working quickly, then iteratively improving them based on actual usage patterns. In his latest course <a href="https://solveit.fast.ai/">SolveIt</a>, Howard extends this iterative philosophy to <a href="{{ site.baseurl }}{% link _posts/2024-11-15-dialogue-engineering.md %}">Dialogue Engineering</a>, i.e. using Large Language Models in an iterative conversation to develop solutions, demonstrating how modern AI can be integrated into the development workflow while maintaining the principles of continuous refinement.</p>
<h3>
Grant Sanderson‚Äôs Visual Mathematics</h3>
<p>
This iterative philosophy extends to mathematical animations. In Grant Sanderson‚Äôs <a href="https://www.youtube.com/watch?v=rbu7Zu5X1zI">How I animate</a> video, he demonstrates how he builds visualisations incrementally, starting with basic shapes and gradually refining them while continuously previewing the results. This approach allows for creative exploration while maintaining momentum.</p>
<h3>
The Problem with Traditional Testing</h3>
<p>
Traditional unit testing often fragments development workflow by requiring separate test maintenance and can lead to ossified code structures. When tests aren‚Äôt exercised regularly, they become outdated, creating false confidence. This is particularly problematic in rapidly evolving domains like AI, where interfaces and requirements frequently change.</p>
<h2>
Conclusion</h2>
<p>
Instead of extensive unit test suites, it‚Äôs worth considering:</p>
<ol>
  <li>
Writing working code first  </li>
  <li>
Using doctests for critical functions  </li>
  <li>
Relying on end-to-end validation  </li>
  <li>
Refactoring based on actual usage patterns  </li>
  <li>
Keeping tests focused on stable interfaces  </li>
</ol>
<p>
This approach reduces maintenance burden while ensuring code remains reliable where it matters most, that is in production.</p>
<p>
‚Äú<em>Programs must be written for people to read, and only incidentally for machines to execute</em>‚Äú- Abelson &amp; Sussman. The same applies to tests.</p>
<hr class="thin">
<p>
[^1]: Python has supported</p>
<pre><code>[doctests](https://docs.python.org/3/library/doctest.html) natively since
v2.6.9</code></pre>

      </div>
    </article>
  </main>

  <footer>
    <div class="container">
      <p>Created with <a href="https://github.com/ai-mindset/init.vim">Neovim</a>, using <a href="https://ai-mindset.github.io/dialogue-engineering">AI</a> to help process and curate content ‚ú®</p>
    </div>
  </footer>

  <script src="/script.js"></script>
</body>
</html>