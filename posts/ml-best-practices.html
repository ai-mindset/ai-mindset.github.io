<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>ðŸ”§ A 5-Minute Guide to Engineering Machine Learning Systems - Just-in-Time Learning</title>
  <link rel="stylesheet" href="/style.css">
</head>
<body>
  <header>
    <div class="container">
      <h1><a href="/">Just-in-Time Learning</a></h1>
    </div>
  </header>

  <main class="post-container">
    <article class="post">
      <header class="post-header">
        <h1>ðŸ”§ A 5-Minute Guide to Engineering Machine Learning Systems</h1>
        <span class="post-date">January 21, 2025</span>
        <div class="post-tags">
          <span class="post-tag">machine-learning</span><span class="post-tag">best-practices</span><span class="post-tag">mlops</span><span class="post-tag">monitoring</span><span class="post-tag">production</span><span class="post-tag">quality-assurance</span><span class="post-tag">data-science</span><span class="post-tag">decision-making</span>
        </div>
      </header>
      
      <div class="post-content">
        <p><strong>TL;DR:</strong> This concise guide distils Google&#39;s 43 machine learning best practices into essential principles across four phases: starting with simple heuristics before ML, building robust data pipelines, prioritising feature engineering over complex algorithms, and gradually introducing complexity only after monitoring systems are established- emphasising engineering excellence over ML expertise.</p>
<!--more-->

<h2>Introduction</h2>
<p>This is a concise reference guide distilling Martin Zinkevich&#39;s <a href="https://developers.google.com/machine-learning/guides/rules-of-ml">influential Google article on machine learning best practices</a>. While the original spans 43 detailed rules, this 10-minute summary captures the essential principles for building production ML systems. Whether you&#39;re starting a new project or reviewing an existing one, this summary can be used as a practical checklist for engineering-focused machine learning.</p>
<h2>Core Philosophy</h2>
<blockquote>
<p>Do machine learning like the great engineer you are, not like the great &gt; machine learning expert you aren&#39;t.</p>
</blockquote>
<p>Most ML gains come from great features, not algorithms. The basic approach should be:</p>
<ol>
<li>Ensure solid end-to-end pipeline</li>
<li>Start with reasonable objective</li>
<li>Add common-sense features simply</li>
<li>Maintain pipeline integrity</li>
</ol>
<h2>Phase I: Before Machine Learning (Rules #1-3)</h2>
<ol>
<li><p><strong>Don&#39;t be afraid to launch without ML</strong><br>-Simple heuristics get you 50% of the way    -Launch with heuristics when data is insufficient    -Example: Use install rate for app ranking</p>
</li>
<li><p><strong>First, design and implement metrics</strong><br>-Track everything possible in current system    -Get early permission from users    -Design systems with metric instrumentation    -Implement experiment framework</p>
</li>
<li><p><strong>Choose ML over complex heuristics</strong><br>-Simple heuristics for launching    -Complex heuristics become unmaintainable    -ML models are easier to maintain long-term</p>
</li>
</ol>
<h2>Phase II: First Pipeline (Rules #4-11)</h2>
<ol>
<li><p><strong>Keep first model simple, get infrastructure right</strong><br>-Focus on data pipeline integrity    -Define clear evaluation metrics    -Plan model integration carefully</p>
</li>
<li><p><strong>Pipeline Health is Critical</strong><br>-Test infrastructure independently    -Monitor freshness requirements    -Watch for silent failures    -Give feature columns owners    -Document feature expectations</p>
</li>
<li><p><strong>Starting Your ML System</strong><br>-Test getting data into algorithm    -Test getting models out correctly    -Monitor data statistics continuously    -Build alerting system</p>
</li>
</ol>
<h2>Your First Objective (Rules #12-15)</h2>
<ol>
<li><p><strong>Choose Objectives Wisely</strong><br>-Don&#39;t overthink initial objective choice    -Start with simple, observable metrics    -Use directly observed user behaviours    -Example: clicks, downloads, shares</p>
</li>
<li><p><strong>Model Selection Guidelines</strong><br>-Start with interpretable models    -Separate spam filtering from quality ranking    -Use simple linear models initially    -Make debugging easier</p>
</li>
</ol>
<h2>Phase III: Feature Engineering (Rules #16-22)</h2>
<ol>
<li><p><strong>Plan to launch and iterate</strong><br>-Expect regular model updates    -Design for feature flexibility    -Keep infrastructure clean</p>
</li>
<li><p><strong>Feature Engineering Principles</strong><br>-Start with directly observed features    -Use cross-product features wisely    -Clean up unused features    -Scale feature complexity with data</p>
</li>
<li><p><strong>Feature Coverage and Quality</strong><br>-Features that generalise across contexts    -Monitor feature coverage    -Document feature ownership    -Regular feature clean-up</p>
</li>
</ol>
<h2>Human Analysis (Rules #23-28)</h2>
<ol>
<li><p><strong>Testing and Validation</strong><br>-Use crowdsourcing or live experiments    -Measure model deltas explicitly    -Look for error patterns    -Consider long-term effects</p>
</li>
<li><p><strong>Common Pitfalls</strong><br>-Engineers aren&#39;t typical users    -Beware of confirmation bias    -Quantify undesirable behaviours</p>
</li>
</ol>
<h2>Training-Serving Skew (Rules #29-37)</h2>
<ol>
<li><p><strong>Prevent Skew</strong><br>-Save serving-time features    -Weight sampled data properly    -Reuse code between training/serving    -Test on future data</p>
</li>
<li><p><strong>Monitor Everything</strong><br>-Track performance metrics    -Watch data distributions    -Monitor feature coverage    -Check prediction bias</p>
</li>
</ol>
<h2>Phase IV: Optimisation and Complex Models (Rules #38-43)</h2>
<ol>
<li><p><strong>When to Add Complexity</strong><br>-After simple approaches plateau    -When objectives are well-aligned    -If maintenance cost justifies gains</p>
</li>
<li><p><strong>Advanced Techniques</strong><br>-Keep ensembles simple    -Look for new information sources    -Balance complexity vs. benefits</p>
</li>
</ol>
<h2>Final Recommendations</h2>
<ol>
<li><p><strong>Launch Decisions</strong><br>-Consider multiple metrics    -Use proxies for long-term goals    -Balance simple vs. complex</p>
</li>
<li><p><strong>System Evolution</strong><br>-Start simple, add complexity gradually    -Monitor consistently    -Keep infrastructure clean    -Document everything</p>
</li>
</ol>

      </div>
    </article>
  </main>

  <footer>
    <div class="container">
      <p>Created with <a href="https://github.com/ai-mindset/init.vim">Neovim</a>, using <a href="https://ai-mindset.github.io/dialogue-engineering">AI</a> to help process and curate content âœ¨</p>
    </div>
  </footer>

  <script src="/script.js"></script>
</body>
</html>