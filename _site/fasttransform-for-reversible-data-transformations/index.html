<!DOCTYPE html>
<html lang="en"><head>
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1"><!-- Begin Jekyll SEO tag v2.8.0 -->
<title>‚è™ Making Data Transformations Reversible with fasttransform | Just-in-Time learning</title>
<meta name="generator" content="Jekyll v3.10.0" />
<meta property="og:title" content="‚è™ Making Data Transformations Reversible with fasttransform" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="Inquisitive. Learning. Sharing. Simplicity = Reliability" />
<meta property="og:description" content="Inquisitive. Learning. Sharing. Simplicity = Reliability" />
<link rel="canonical" href="http://0.0.0.0:4000/fasttransform-for-reversible-data-transformations/" />
<meta property="og:url" content="http://0.0.0.0:4000/fasttransform-for-reversible-data-transformations/" />
<meta property="og:site_name" content="Just-in-Time learning" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2025-03-22T00:00:00+00:00" />
<meta name="twitter:card" content="summary" />
<meta property="twitter:title" content="‚è™ Making Data Transformations Reversible with fasttransform" />
<script type="application/ld+json">
{"@context":"https://schema.org","@type":"BlogPosting","dateModified":"2025-03-22T00:00:00+00:00","datePublished":"2025-03-22T00:00:00+00:00","description":"Inquisitive. Learning. Sharing. Simplicity = Reliability","headline":"‚è™ Making Data Transformations Reversible with fasttransform","mainEntityOfPage":{"@type":"WebPage","@id":"http://0.0.0.0:4000/fasttransform-for-reversible-data-transformations/"},"url":"http://0.0.0.0:4000/fasttransform-for-reversible-data-transformations/"}</script>
<!-- End Jekyll SEO tag -->
<link href="https://unpkg.com/@primer/css/dist/primer.css" rel="stylesheet" />
<link rel="stylesheet" href="/assets/main.css"><link type="application/atom+xml" rel="alternate" href="http://0.0.0.0:4000/feed.xml" title="Just-in-Time learning" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/katex.min.css" integrity="sha384-zB1R0rpPzHqg7Kpt0Aljp8JPLqbXI3bhnPWROx27a9N0Ll6ZP/+DiW/UqRcLbRjq" crossorigin="anonymous">
<script type="text/javascript" async src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-MML-AM_CHTML"> </script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/katex.min.js" integrity="sha384-y23I5Q6l+B6vatafAwxRu/0oK/79VlbSz7Q9aiSZUvyWYIYsd+qj+o24G5ZU2zJz" crossorigin="anonymous"></script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/contrib/auto-render.min.js" integrity="sha384-kWPLUVMOks5AQFrykwIup5lo0m3iMkkHrD0uJ4H5cjeGihAutqP0yW0J6dpFiVkI" crossorigin="anonymous"></script>
<script>
document.addEventListener("DOMContentLoaded", function() {
        renderMathInElement( document.body, {
delimiters: [
{left: "$$", right: "$$", display: true},
{left: "[%", right: "%]", display: true},
{left: "$", right: "$", display: false}
]}
);
        });
</script>


<script>
function wrap_img(fn) {
    if (document.attachEvent ? document.readyState === "complete" : document.readyState !== "loading") {
        var elements = document.querySelectorAll(".post img");
        Array.prototype.forEach.call(elements, function(el, i) {
                if (el.getAttribute("title")) {
                const caption = document.createElement('figcaption');
                var node = document.createTextNode(el.getAttribute("title"));
                caption.appendChild(node);
                const wrapper = document.createElement('figure');
                wrapper.className = 'image';
                el.parentNode.insertBefore(wrapper, el);
                el.parentNode.removeChild(el);
                wrapper.appendChild(el);
                wrapper.appendChild(caption);
                }
                });
    } else { document.addEventListener('DOMContentLoaded', fn); }
}
window.onload = wrap_img;
</script>











<link rel="stylesheet" href="/assets/css/style.css">
<script src="/assets/js/theme.js"></script>

</head>
<body><script src="https://cdnjs.cloudflare.com/ajax/libs/lunr.js/2.3.9/lunr.min.js"></script>
<script src="/assets/js/search.js"></script>

<header class="site-header">
  <div class="wrapper">
    <a class="site-title" rel="author" href="/">Just-in-Time learning</a>
    <nav class="site-nav">
      <input type="checkbox" id="nav-trigger" class="nav-trigger" />
      <label for="nav-trigger">
        <span class="menu-icon">
          <svg viewBox="0 0 18 15" width="18px" height="15px">
            <path
              d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.032C17.335,0,18,0.665,18,1.484L18,1.484z M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.032C17.335,6.031,18,6.696,18,7.516L18,7.516z M18,13.516C18,14.335,17.335,15,16.516,15H1.484 C0.665,15,0,14.335,0,13.516l0,0c0-0.82,0.665-1.484,1.484-1.484h15.032C17.335,12.031,18,12.696,18,13.516L18,13.516z" />
          </svg>
        </span>
      </label>

      <div class="trigger">
        <div class="search-container">
          <input type="text" id="search-input" placeholder="Search..." aria-label="Search posts" class="search-input">
          <div id="search-results" class="search-results"></div>
        </div>
        <a class="page-link" href="/aihub">AI Hub</a>
        <a class="page-link" href="/about">About</a>
        <button class="theme-toggle" onclick="toggleTheme()" id="theme-toggle">
  üåô Dark
</button>

<script>
function toggleTheme() {
    const body = document.querySelector('body');
    const button = document.getElementById('theme-toggle');
    const isDark = body.classList.toggle('dark-theme');
    
    button.innerHTML = isDark ? '‚òÄÔ∏è Light' : 'üåô Dark';
    localStorage.setItem('darkTheme', isDark);
}

document.addEventListener('DOMContentLoaded', function() {
    if (localStorage.getItem('darkTheme') === 'true') {
        document.querySelector('body').classList.add('dark-theme');
        document.getElementById('theme-toggle').innerHTML = '‚òÄÔ∏è Light';
    }
});
</script>

      </div>
    </nav>
  </div>
</header>
<main class="page-content" aria-label="Content">
      <div class="wrapper">
        <article class="post">
  <h1>‚è™ Making Data Transformations Reversible with fasttransform</h1>
  
  <!-- Debug info -->
  <!-- <div style="color: red;"> -->
  <!--   TOC enabled: true -->
  <!--   Layout: post -->
  <!-- </div> -->
  
  
    <nav class="toc">
  <div class="toc-header">
    <h2>Contents</h2>
    <button class="toc-toggle" aria-label="Toggle table of contents">
      <svg class="toc-icon" viewBox="0 0 24 24" width="24" height="24">
        <path class="chevron-down" d="M6 9l6 6 6-6"></path>
      </svg>
    </button>
  </div>
  <div class="toc-content">
    <ul>
      
      
        
      
        
          
          <li class="toc-level-2">
            <a href="#introduction">Introduction</a>
            
            
            
          </li>
        
      
        
          
          <li class="toc-level-2">
            <a href="#reversible-pipelines-made-simple">Reversible Pipelines Made Simple</a>
            
            
            
              <ul>
                
                  
                
                  
                    
                    <li class="toc-level-3">
                      <a href="#the-problem-with-one-way-transforms">The Problem with One-Way Transforms</a>
                    </li>
                  
                
                  
                    
                    <li class="toc-level-3">
                      <a href="#an-elegant-solution">An Elegant Solution</a>
                    </li>
                  
                
                  
                    
                    <li class="toc-level-3">
                      <a href="#multiple-dispatch-the-secret-sauce">Multiple Dispatch: The Secret Sauce</a>
                    </li>
                  
                
                  
                    
                    <li class="toc-level-3">
                      <a href="#connections-to-julia-s-multiple-dispatch">Connections to Julia‚Äôs Multiple Dispatch</a>
                    </li>
                  
                
              </ul>
            
          </li>
        
      
        
          
          <li class="toc-level-2">
            <a href="#conclusion">Conclusion</a>
            
            
            
          </li>
        
      
    </ul>
  </div>
</nav>

  
  
  <!--more-->

<h2 id="introduction">Introduction</h2>

<p>Machine learning practitioners face a common problem: after applying multiple transformations to prepare data for training, it becomes difficult to visualise what the model actually sees. This visualisation gap makes debugging challenging and often leads to missing critical insights about model behaviour.<br />
For example, consider a model built to distinguish wolves from huskies that performs poorly on certain images. Without the ability to easily inspect how transformations affect the input data, one might miss that the model is actually detecting snow (common in wolf photos) rather than the animals themselves.<br />
Fast.ai‚Äôs solution to this problem is <a href="https://github.com/AnswerDotAI/fasttransform">fasttransform</a><sup id="fnref:1" role="doc-noteref"><a href="#fn:1" class="footnote" rel="footnote">1</a></sup>, a library that ensures any transformation applied to data can be easily reversed. Let‚Äôs explore how it works and why it matters.</p>

<h2 id="reversible-pipelines-made-simple">Reversible Pipelines Made Simple</h2>

<h3 id="the-problem-with-one-way-transforms">The Problem with One-Way Transforms</h3>

<p>Traditional data transformation pipelines in libraries like PyTorch are one-way streets. Consider this simple example of normalising an image:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">torchvision</span> <span class="kn">import</span> <span class="n">transforms</span> <span class="k">as</span> <span class="n">T</span>
<span class="n">transforms_pt</span> <span class="o">=</span> <span class="n">T</span><span class="p">.</span><span class="n">Compose</span><span class="p">([</span>
    <span class="n">T</span><span class="p">.</span><span class="n">Resize</span><span class="p">(</span><span class="mi">256</span><span class="p">),</span>
    <span class="n">T</span><span class="p">.</span><span class="n">CenterCrop</span><span class="p">(</span><span class="mi">224</span><span class="p">),</span>
    <span class="n">T</span><span class="p">.</span><span class="n">ToTensor</span><span class="p">(),</span>
    <span class="n">T</span><span class="p">.</span><span class="n">Normalize</span><span class="p">(</span><span class="o">*</span><span class="n">imagenet_stats</span><span class="p">)</span>
<span class="p">])</span>

<span class="n">img</span> <span class="o">=</span> <span class="n">Image</span><span class="p">.</span><span class="nb">open</span><span class="p">(</span><span class="s">"husky.jpeg"</span><span class="p">)</span>
<span class="n">img_transformed</span> <span class="o">=</span> <span class="n">transforms_pt</span><span class="p">(</span><span class="n">img</span><span class="p">)</span>
</code></pre></div></div>

<p>Attempting to visualise <code class="language-plaintext highlighter-rouge">img_transformed</code> results in a mess of pixel values outside the displayable range. To see what the model sees, one needs to manually write an inverse transform function:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">decode_pt</span><span class="p">(</span><span class="n">tensor</span><span class="p">,</span> <span class="n">mean</span><span class="p">,</span> <span class="n">std</span><span class="p">):</span>
    <span class="n">out</span> <span class="o">=</span> <span class="n">tensor</span><span class="p">.</span><span class="n">clone</span><span class="p">()</span>
    <span class="k">for</span> <span class="n">t</span><span class="p">,</span> <span class="n">m</span><span class="p">,</span> <span class="n">s</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">out</span><span class="p">,</span> <span class="n">mean</span><span class="p">,</span> <span class="n">std</span><span class="p">):</span> <span class="n">t</span><span class="p">.</span><span class="n">mul_</span><span class="p">(</span><span class="n">s</span><span class="p">).</span><span class="n">add_</span><span class="p">(</span><span class="n">m</span><span class="p">)</span>
    <span class="n">out</span> <span class="o">=</span> <span class="n">out</span><span class="p">.</span><span class="n">mul</span><span class="p">(</span><span class="mi">255</span><span class="p">).</span><span class="n">clamp</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">255</span><span class="p">).</span><span class="n">byte</span><span class="p">()</span>
    <span class="k">return</span> <span class="n">out</span>
</code></pre></div></div>

<p>This is tedious and error-prone, especially as your transformation pipeline grows more complex.</p>

<h3 id="an-elegant-solution">An Elegant Solution</h3>

<p>fasttransform takes a fundamentally different approach by pairing each transformation with its inverse. Here‚Äôs the same pipeline using fasttransform:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">fastai.vision.all</span> <span class="kn">import</span> <span class="o">*</span>

<span class="n">transforms_ft</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">([</span>
   <span class="n">PILImage</span><span class="p">.</span><span class="n">create</span><span class="p">,</span>
   <span class="n">Resize</span><span class="p">(</span><span class="mi">256</span><span class="p">,</span> <span class="n">method</span><span class="o">=</span><span class="s">"squish"</span><span class="p">),</span>
   <span class="n">Resize</span><span class="p">(</span><span class="mi">224</span><span class="p">,</span> <span class="n">method</span><span class="o">=</span><span class="s">"crop"</span><span class="p">),</span>
   <span class="n">ToTensor</span><span class="p">(),</span>
   <span class="n">IntToFloatTensor</span><span class="p">(),</span>
   <span class="n">Normalize</span><span class="p">.</span><span class="n">from_stats</span><span class="p">(</span><span class="o">*</span><span class="n">imagenet_stats</span><span class="p">)</span>
<span class="p">])</span>

<span class="c1"># Transform our image
</span><span class="n">fpath</span> <span class="o">=</span> <span class="n">Path</span><span class="p">(</span><span class="s">"./huskies_vs_wolves/train/husky/husky_0.jpeg"</span><span class="p">)</span>
<span class="n">img_transformed</span> <span class="o">=</span> <span class="n">transforms_ft</span><span class="p">(</span><span class="n">fpath</span><span class="p">)</span>
<span class="c1"># To reverse the transformations:
</span><span class="n">img_decoded</span> <span class="o">=</span> <span class="n">transforms_ft</span><span class="p">.</span><span class="n">decode</span><span class="p">(</span><span class="n">img_transformed</span><span class="p">)</span>
</code></pre></div></div>

<p>The magic lies in how each transform defines both forward and reverse operations:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">class</span> <span class="nc">Normalize</span><span class="p">(</span><span class="n">Transform</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">mean</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">std</span><span class="o">=</span><span class="bp">None</span><span class="p">):</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">mean</span> <span class="o">=</span> <span class="n">mean</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">std</span> <span class="o">=</span> <span class="n">std</span>
        
    <span class="k">def</span> <span class="nf">encodes</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span> <span class="k">return</span> <span class="p">(</span><span class="n">x</span><span class="o">-</span><span class="bp">self</span><span class="p">.</span><span class="n">mean</span><span class="p">)</span> <span class="o">/</span> <span class="bp">self</span><span class="p">.</span><span class="n">std</span>  <span class="c1"># forward transform
</span>    <span class="k">def</span> <span class="nf">decodes</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span> <span class="k">return</span> <span class="n">x</span><span class="o">*</span><span class="bp">self</span><span class="p">.</span><span class="n">std</span> <span class="o">+</span> <span class="bp">self</span><span class="p">.</span><span class="n">mean</span>    <span class="c1"># inverse transform
</span></code></pre></div></div>

<p>By defining both <code class="language-plaintext highlighter-rouge">encodes</code> and <code class="language-plaintext highlighter-rouge">decodes</code> methods, fasttransform automatically knows how to reverse your transformations. This is particularly valuable when working with fast.ai v2, where this kind of visualisation capability is built directly into core functions like <code class="language-plaintext highlighter-rouge">show_batch</code> and <code class="language-plaintext highlighter-rouge">show_results</code>.</p>

<h3 id="multiple-dispatch-the-secret-sauce">Multiple Dispatch: The Secret Sauce</h3>

<p>Another powerful feature of fasttransform is how it handles different types of data. Using a concept called <a href="https://www.youtube.com/watch?v=kc9HwsxE1OY">multiple dispatch</a><sup id="fnref:2" role="doc-noteref"><a href="#fn:2" class="footnote" rel="footnote">2</a></sup>, transformations can apply differently based on the type of data they receive.</p>

<p>This becomes particularly valuable when dealing with images and their labels, allowing a single pipeline to handle both:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Function that loads both image and its label
</span><span class="k">def</span> <span class="nf">load_img_and_label</span><span class="p">(</span><span class="n">fp</span><span class="p">):</span> <span class="k">return</span> <span class="n">PILImage</span><span class="p">.</span><span class="n">create</span><span class="p">(</span><span class="n">fp</span><span class="p">),</span> <span class="n">parent_label</span><span class="p">(</span><span class="n">fp</span><span class="p">)</span>

<span class="n">transforms_ft</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">([</span>
   <span class="n">load_img_and_label</span><span class="p">,</span>  <span class="c1"># Loads both image and label as a tuple
</span>   <span class="n">Resize</span><span class="p">(</span><span class="mi">256</span><span class="p">,</span> <span class="n">method</span><span class="o">=</span><span class="s">"squish"</span><span class="p">),</span>
   <span class="n">Resize</span><span class="p">(</span><span class="mi">224</span><span class="p">,</span> <span class="n">method</span><span class="o">=</span><span class="s">"crop"</span><span class="p">),</span>
   <span class="n">ToTensor</span><span class="p">(),</span>
   <span class="n">IntToFloatTensor</span><span class="p">(),</span>
   <span class="n">Normalize</span><span class="p">.</span><span class="n">from_stats</span><span class="p">(</span><span class="o">*</span><span class="n">imagenet_stats</span><span class="p">)</span>
<span class="p">])</span>
</code></pre></div></div>

<p>The pipeline intelligently applies each transform only to the appropriate data types, eliminating the need for separate transformation pipelines.</p>

<h3 id="connections-to-julias-multiple-dispatch">Connections to Julia‚Äôs Multiple Dispatch</h3>

<p>Interestingly, the concept of multiple dispatch that fasttransform leverages is a core feature of the Julia programming language. In Julia, which method of a function gets called depends on the types of all arguments, not just the first one (as in traditional object-oriented programming).<br />
As explained in Julia‚Äôs documentation: ‚Äú<em>Using all of a function‚Äôs arguments to choose which method should be invoked, rather than just the first, is known as multiple dispatch. Multiple dispatch is particularly useful for mathematical code, where it makes little sense to artificially deem the operations to ‚Äòbelong‚Äô to one argument more than any of the others</em>‚Äù.<br />
The connection to Julia is particularly illuminating, as it demonstrates how concepts from one language can inspire powerful design patterns in another. Just as Julia‚Äôs multiple dispatch enables elegant mathematical code, fasttransform‚Äôs implementation of this concept allows for cleaner, more intuitive data pipelines in Python.</p>

<h2 id="conclusion">Conclusion</h2>

<p>fasttransform represents a significant step forward in making machine learning workflows more intuitive and debugging more accessible. By making transformations reversible through paired encode/decode methods and leveraging multiple dispatch to handle different data types intelligently, it solves two fundamental problems in data processing pipelines: the inability to easily reverse transformations to inspect data, and the need for separate transformation pipelines for different types of data.<br />
The ability to easily visualise transformed data isn‚Äôt just convenient -it‚Äôs essential for understanding model behaviour and catching issues like the wolf/husky example, where models learn spurious correlations rather than intended features.<br />
As machine learning systems grow more complex, tools like fasttransform that improve transparency and the ability to debug become increasingly valuable. Whether working with images, text, time series, or other data types, being able to see what a model sees provides critical insights that might otherwise be missed.<br />
Returning to our wolf/husky example, the ability to easily visualise transformed data allows researchers to immediately identify that their model is learning to detect snow backgrounds rather than animal features -a crucial insight for building more robust models.<br />
Those interested in trying fasttransform can install it with <code class="language-plaintext highlighter-rouge">pip install fasttransform</code> and check out the <a href="https://github.com/AnswerDotAI/fasttransform">official fasttransform documentation</a> for more examples and detailed API references. The library offers these capabilities with minimal performance overhead, as the paired transformation approach adds negligible computational cost while providing significant benefits for debugging and understanding model behaviour.</p>

<hr />
<div class="footnotes" role="doc-endnotes">
  <ol>
    <li id="fn:1" role="doc-endnote">
      <p>Rens Dimmendaal, Hamel Husain, &amp; Jeremy Howard. ‚Äú<a href="https://www.fast.ai/posts/2025-02-20-fasttransform.html">fasttransform: Reversible Pipelines Made Simple</a>‚Äù fast.ai blog, February 20, 2025.¬†<a href="#fnref:1" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
    <li id="fn:2" role="doc-endnote">
      <p>‚Äú<a href="https://docs.julialang.org/en/v1/manual/methods/">Methods ¬∑ The Julia Language</a>‚Äù Julia Documentation, docs.julialang.org.¬†<a href="#fnref:2" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
  </ol>
</div>

</article>

<!-- Theme toggle -->
<script>
// Initialize theme from localStorage
if (localStorage.getItem('darkTheme') === 'true') {
    document.body.classList.add('dark-theme');
}
</script>

<!-- Collapsible TOC -->
<script>
document.addEventListener('DOMContentLoaded', function() {
  const tocHeader = document.querySelector('.toc-header');
  const toc = document.querySelector('.toc');
  
  if (tocHeader && toc) {
    tocHeader.addEventListener('click', function() {
      toc.classList.toggle('collapsed');
      
      // Optional: Save state to localStorage
      localStorage.setItem('tocCollapsed', toc.classList.contains('collapsed'));
    });
    
    // Optional: Restore state from localStorage
    const isCollapsed = localStorage.getItem('tocCollapsed') === 'true';
    if (isCollapsed) {
      toc.classList.add('collapsed');
    }
  }
});
</script>

<div class="post-tags">
  Tags: 
  
    <a href="/">machine-learning</a>, 
  
    <a href="/">data-processing</a>, 
  
    <a href="/">fast-ai</a>, 
  
    <a href="/">python</a>, 
  
    <a href="/">data-science</a>, 
  
    <a href="/">optimisation</a>, 
  
    <a href="/">best-practices</a>, 
  
    <a href="/">interpretability</a>
  
</div>


      </div>
    </main><footer class="site-footer h-card">
  <data class="u-url" href="/"></data>

  <div class="wrapper">

    <h2 class="footer-heading">Just-in-Time learning</h2>

    <div class="footer-col-wrapper">
      <div class="footer-col footer-col-1">
        <ul class="contact-list">
          <li class="p-name">Just-in-Time learning</li></ul>
      </div>

      <div class="footer-col footer-col-2"><ul class="social-media-list">
  <li><a href="https://github.com/ai-mindset"><svg class="svg-icon"><use xlink:href="/assets/minima-social-icons.svg#github"></use></svg> <span class="username">ai-mindset</span></a></li></ul>
</div>

      <div class="footer-col footer-col-3">
        <p>Inquisitive. Learning. Sharing. Simplicity = Reliability</p>
      </div>
    </div>

  </div>

</footer>
</body>

</html>
