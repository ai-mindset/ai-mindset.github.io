<!DOCTYPE html>
<html lang="en"><head>
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1"><!-- Begin Jekyll SEO tag v2.8.0 -->
<title>üß† RAG vs CAG: Understanding Knowledge Augmentation in LLMs | Just-in-Time learning</title>
<meta name="generator" content="Jekyll v3.10.0" />
<meta property="og:title" content="üß† RAG vs CAG: Understanding Knowledge Augmentation in LLMs" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="Inquisitive. Learning. Sharing. Simplicity = Reliability" />
<meta property="og:description" content="Inquisitive. Learning. Sharing. Simplicity = Reliability" />
<link rel="canonical" href="http://0.0.0.0:4000/rag-or-cag/" />
<meta property="og:url" content="http://0.0.0.0:4000/rag-or-cag/" />
<meta property="og:site_name" content="Just-in-Time learning" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2025-03-18T00:00:00+00:00" />
<meta name="twitter:card" content="summary" />
<meta property="twitter:title" content="üß† RAG vs CAG: Understanding Knowledge Augmentation in LLMs" />
<script type="application/ld+json">
{"@context":"https://schema.org","@type":"BlogPosting","dateModified":"2025-03-18T00:00:00+00:00","datePublished":"2025-03-18T00:00:00+00:00","description":"Inquisitive. Learning. Sharing. Simplicity = Reliability","headline":"üß† RAG vs CAG: Understanding Knowledge Augmentation in LLMs","mainEntityOfPage":{"@type":"WebPage","@id":"http://0.0.0.0:4000/rag-or-cag/"},"url":"http://0.0.0.0:4000/rag-or-cag/"}</script>
<!-- End Jekyll SEO tag -->
<link href="https://unpkg.com/@primer/css/dist/primer.css" rel="stylesheet" />
<link rel="stylesheet" href="/assets/main.css"><link type="application/atom+xml" rel="alternate" href="http://0.0.0.0:4000/feed.xml" title="Just-in-Time learning" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/katex.min.css" integrity="sha384-zB1R0rpPzHqg7Kpt0Aljp8JPLqbXI3bhnPWROx27a9N0Ll6ZP/+DiW/UqRcLbRjq" crossorigin="anonymous">
<script type="text/javascript" async src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-MML-AM_CHTML"> </script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/katex.min.js" integrity="sha384-y23I5Q6l+B6vatafAwxRu/0oK/79VlbSz7Q9aiSZUvyWYIYsd+qj+o24G5ZU2zJz" crossorigin="anonymous"></script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/contrib/auto-render.min.js" integrity="sha384-kWPLUVMOks5AQFrykwIup5lo0m3iMkkHrD0uJ4H5cjeGihAutqP0yW0J6dpFiVkI" crossorigin="anonymous"></script>
<script>
document.addEventListener("DOMContentLoaded", function() {
        renderMathInElement( document.body, {
delimiters: [
{left: "$$", right: "$$", display: true},
{left: "[%", right: "%]", display: true},
{left: "$", right: "$", display: false}
]}
);
        });
</script>


<script>
function wrap_img(fn) {
    if (document.attachEvent ? document.readyState === "complete" : document.readyState !== "loading") {
        var elements = document.querySelectorAll(".post img");
        Array.prototype.forEach.call(elements, function(el, i) {
                if (el.getAttribute("title")) {
                const caption = document.createElement('figcaption');
                var node = document.createTextNode(el.getAttribute("title"));
                caption.appendChild(node);
                const wrapper = document.createElement('figure');
                wrapper.className = 'image';
                el.parentNode.insertBefore(wrapper, el);
                el.parentNode.removeChild(el);
                wrapper.appendChild(el);
                wrapper.appendChild(caption);
                }
                });
    } else { document.addEventListener('DOMContentLoaded', fn); }
}
window.onload = wrap_img;
</script>











<link rel="stylesheet" href="/assets/css/style.css">
<script src="/assets/js/theme.js"></script>

</head>
<body><script src="https://cdnjs.cloudflare.com/ajax/libs/lunr.js/2.3.9/lunr.min.js"></script>
<script src="/assets/js/search.js"></script>

<header class="site-header">
  <div class="wrapper">
    <a class="site-title" rel="author" href="/">Just-in-Time learning</a>
    <nav class="site-nav">
      <input type="checkbox" id="nav-trigger" class="nav-trigger" />
      <label for="nav-trigger">
        <span class="menu-icon">
          <svg viewBox="0 0 18 15" width="18px" height="15px">
            <path
              d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.032C17.335,0,18,0.665,18,1.484L18,1.484z M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.032C17.335,6.031,18,6.696,18,7.516L18,7.516z M18,13.516C18,14.335,17.335,15,16.516,15H1.484 C0.665,15,0,14.335,0,13.516l0,0c0-0.82,0.665-1.484,1.484-1.484h15.032C17.335,12.031,18,12.696,18,13.516L18,13.516z" />
          </svg>
        </span>
      </label>

      <div class="trigger">
        <div class="search-container">
          <input type="text" id="search-input" placeholder="Search..." aria-label="Search posts" class="search-input">
          <div id="search-results" class="search-results"></div>
        </div>
        <a class="page-link" href="/aihub">AI Hub</a>
        <a class="page-link" href="/about">About</a>
        <button class="theme-toggle" onclick="toggleTheme()" id="theme-toggle">
  üåô Dark
</button>

<script>
function toggleTheme() {
    const body = document.querySelector('body');
    const button = document.getElementById('theme-toggle');
    const isDark = body.classList.toggle('dark-theme');
    
    button.innerHTML = isDark ? '‚òÄÔ∏è Light' : 'üåô Dark';
    localStorage.setItem('darkTheme', isDark);
}

document.addEventListener('DOMContentLoaded', function() {
    if (localStorage.getItem('darkTheme') === 'true') {
        document.querySelector('body').classList.add('dark-theme');
        document.getElementById('theme-toggle').innerHTML = '‚òÄÔ∏è Light';
    }
});
</script>

      </div>
    </nav>
  </div>
</header>
<main class="page-content" aria-label="Content">
      <div class="wrapper">
        <article class="post">
  <h1>üß† RAG vs CAG: Understanding Knowledge Augmentation in LLMs</h1>

  <div class="post-meta">
    <span class="post-date">Mar 18, 2025</span>
    <span class="reading-time">





  4 minutes read

</span>
  </div>
  
  <!-- Debug info -->
  <!-- <div style="color: red;"> -->
  <!--   TOC enabled: true -->
  <!--   Layout: post -->
  <!-- </div> -->
  
  
    <nav class="toc">
  <div class="toc-header">
    <h2>Contents</h2>
    <button class="toc-toggle" aria-label="Toggle table of contents">
      <svg class="toc-icon" viewBox="0 0 24 24" width="24" height="24">
        <path class="chevron-down" d="M6 9l6 6 6-6"></path>
      </svg>
    </button>
  </div>
  <div class="toc-content">
    <ul>
      
      
        
      
        
          
          <li class="toc-level-2">
            <a href="#introduction">Introduction</a>
            
            
            
          </li>
        
      
        
          
          <li class="toc-level-2">
            <a href="#understanding-rag-and-cag">Understanding RAG and CAG</a>
            
            
            
              <ul>
                
                  
                
                  
                    
                    <li class="toc-level-3">
                      <a href="#retrieval-augmented-generation-rag">Retrieval Augmented Generation (RAG)</a>
                    </li>
                  
                
                  
                    
                    <li class="toc-level-3">
                      <a href="#cache-augmented-generation-cag">Cache Augmented Generation (CAG)</a>
                    </li>
                  
                
              </ul>
            
          </li>
        
      
        
          
          <li class="toc-level-2">
            <a href="#comparing-capabilities">Comparing Capabilities</a>
            
            
            
              <ul>
                
                  
                
                  
                    
                    <li class="toc-level-3">
                      <a href="#accuracy">Accuracy</a>
                    </li>
                  
                
                  
                    
                    <li class="toc-level-3">
                      <a href="#latency">Latency</a>
                    </li>
                  
                
                  
                    
                    <li class="toc-level-3">
                      <a href="#scalability">Scalability</a>
                    </li>
                  
                
                  
                    
                    <li class="toc-level-3">
                      <a href="#data-freshness">Data Freshness</a>
                    </li>
                  
                
              </ul>
            
          </li>
        
      
        
          
          <li class="toc-level-2">
            <a href="#when-to-use-each-approach">When to Use Each Approach</a>
            
            
            
          </li>
        
      
        
          
          <li class="toc-level-2">
            <a href="#conclusion">Conclusion</a>
            
            
            
          </li>
        
      
    </ul>
  </div>
</nav>

  
  
  <!--more-->

<h2 id="introduction">Introduction</h2>

<p>Large Language Models (LLMs) face a fundamental knowledge problem: they‚Äôre limited to information present in their training data. This creates challenges when dealing with recent events that occurred after training or proprietary information specific to an organization.<br />
To address these limitations, two primary augmentation techniques have emerged: Retrieval Augmented Generation (RAG) and Cache Augmented Generation (CAG). This article breaks down both approaches based on  <a href="https://www.youtube.com/channel/UCKWaEZ-_VweaEx1j62do_vQ">IBM Technology</a>‚Äôs comprehensive explanation from their <a href="https://youtube.com/watch?v=HdafI0t3sEY">video on RAG vs CAG</a>, examining how they work, their capabilities, and when to use each one.</p>

<h2 id="understanding-rag-and-cag">Understanding RAG and CAG</h2>

<h3 id="retrieval-augmented-generation-rag">Retrieval Augmented Generation (RAG)</h3>

<p>RAG operates through a two-phase system:</p>

<ol>
  <li><strong>Offline Phase (Preparation)</strong>
    <ul>
      <li>Documents are broken into manageable chunks.</li>
      <li>Vector embeddings are created for each chunk using an embedding model.</li>
      <li>These embeddings are stored in a vector database, creating a searchable knowledge index.</li>
    </ul>
  </li>
  <li><strong>Online Phase (Query &amp; Response)</strong>
    <ul>
      <li>The user submits a query.</li>
      <li>The RAG retriever converts this query to a vector using the same embedding model.</li>
      <li>The system performs a similarity search in the vector database.</li>
      <li>It retrieves the most relevant document chunks (typically 3-5 passages).</li>
      <li>These chunks and the user‚Äôs query are placed in the LLM‚Äôs context window.</li>
      <li>The LLM generates an answer based on both the query and the retrieved context.</li>
    </ul>
  </li>
</ol>

<p>For example, if asked <em>‚ÄúWhat film won Best Picture this year?‚Äù</em>, the system might retrieve information about <em>‚ÄúAnora‚Äù</em> winning the award, even if this occurred after the model‚Äôs original training.</p>

<p>A key advantage of RAG is its modularity‚Äîcomponents like the vector database, embedding model, or LLM can be swapped independently without rebuilding the entire system.</p>

<h3 id="cache-augmented-generation-cag">Cache Augmented Generation (CAG)</h3>

<p>CAG takes a fundamentally different approach:</p>

<ul>
  <li>Instead of retrieving knowledge on demand, CAG preloads all available information into the model‚Äôs context window</li>
  <li>The entire knowledge corpus is formatted into one massive prompt that fits within the model‚Äôs context limits</li>
  <li>The LLM processes this extensive input in a single forward pass</li>
  <li>The model‚Äôs internal state is captured in what‚Äôs called a ‚ÄúKV cache‚Äù (key-value cache)</li>
  <li>When a user query arrives, it‚Äôs added to this pre-existing KV cache</li>
  <li>The model can access any relevant information from the cache without reprocessing the entire knowledge base</li>
</ul>

<p>The fundamental distinction: RAG fetches only what it predicts is needed, while CAG loads everything upfront and remembers it for later use.</p>

<h2 id="comparing-capabilities">Comparing Capabilities</h2>

<h3 id="accuracy">Accuracy</h3>
<ul>
  <li><strong>RAG</strong>: Accuracy depends heavily on the retriever component. If the retriever fails to fetch relevant documents, the LLM won‚Äôt have the facts needed to answer correctly.</li>
  <li><strong>CAG</strong>: Guarantees that all information is available (assuming it exists in the knowledge base), but places the burden on the LLM to extract the right information from a large context.</li>
</ul>

<h3 id="latency">Latency</h3>
<ul>
  <li><strong>RAG</strong>: Higher latency due to additional steps of embedding the query, searching the index, and processing retrieved text.</li>
  <li><strong>CAG</strong>: Lower latency once knowledge is cached, as answering queries requires only one forward pass without retrieval lookup time.</li>
</ul>

<h3 id="scalability">Scalability</h3>
<ul>
  <li><strong>RAG</strong>: Can scale to millions of documents as only a small portion is retrieved per query.</li>
  <li><strong>CAG</strong>: Limited by the model‚Äôs context window size (typically ~32k-100k tokens), restricting it to a few hundred documents at most.</li>
</ul>

<h3 id="data-freshness">Data Freshness</h3>
<ul>
  <li><strong>RAG</strong>: Easy to update incrementally as you add new document embeddings or remove outdated ones.</li>
  <li><strong>CAG</strong>: Requires recomputation when data changes, making it less suitable for frequently updated information.</li>
</ul>

<h2 id="when-to-use-each-approach">When to Use Each Approach</h2>

<p>The video presents several scenarios to illustrate when each approach is more appropriate:</p>

<ol>
  <li><strong>IT Help Desk Bot with Static Manual (200 pages, rarely updated)</strong>
    <ul>
      <li><strong>Best Choice</strong>: CAG</li>
      <li><strong>Rationale</strong>: Knowledge base is small enough to fit in most LLM context windows, information is static, and caching enables faster query responses.</li>
    </ul>
  </li>
  <li><strong>Legal Research Assistant (Thousands of constantly updated documents)</strong>
    <ul>
      <li><strong>Best Choice</strong>: RAG</li>
      <li><strong>Rationale</strong>: Knowledge base is massive and dynamic, precise citations are required, and incremental updates are essential.</li>
    </ul>
  </li>
  <li><strong>Clinical Decision Support System (Patient records, treatment guides, drug interactions)</strong>
    <ul>
      <li><strong>Best Choice</strong>: Hybrid Approach</li>
      <li><strong>Rationale</strong>: Use RAG to retrieve relevant subsets from the massive knowledge base, then load that retrieved content into a long-context model using CAG for follow-up questions.</li>
    </ul>
  </li>
</ol>

<h2 id="conclusion">Conclusion</h2>

<p>The choice between RAG and CAG ultimately depends on your specific use case. Consider RAG when dealing with large or frequently updated knowledge sources, when citations are necessary, or when resources for running long-context models are limited. CAG is preferable when working with a fixed knowledge set that fits within your model‚Äôs context window, when low latency is crucial, or when you want to simplify deployment.<br />
As LLM technology evolves with expanding context windows and improved retrieval mechanisms, we may see these approaches converge or new hybrid solutions emerge. For now, understanding the strengths and limitations of both RAG and CAG allows AI engineers to make informed decisions about knowledge augmentation strategies that best suit their specific applications.</p>

</article>

<!-- Theme toggle -->
<script>
// Initialize theme from localStorage
if (localStorage.getItem('darkTheme') === 'true') {
    document.body.classList.add('dark-theme');
}
</script>

<!-- Collapsible TOC -->
<script>
document.addEventListener('DOMContentLoaded', function() {
  const tocHeader = document.querySelector('.toc-header');
  const toc = document.querySelector('.toc');
  
  if (tocHeader && toc) {
    tocHeader.addEventListener('click', function() {
      toc.classList.toggle('collapsed');
      
      // Optional: Save state to localStorage
      localStorage.setItem('tocCollapsed', toc.classList.contains('collapsed'));
    });
    
    // Optional: Restore state from localStorage
    const isCollapsed = localStorage.getItem('tocCollapsed') === 'true';
    if (isCollapsed) {
      toc.classList.add('collapsed');
    }
  }
});
</script>

<div class="post-tags">
  Tags: 
  
    <a href="/">rag</a>, 
  
    <a href="/">llm</a>, 
  
    <a href="/">ai</a>, 
  
    <a href="/">machine-learning</a>, 
  
    <a href="/">prompt-engineering</a>, 
  
    <a href="/">nlp</a>, 
  
    <a href="/">data-processing</a>, 
  
    <a href="/">best-practices</a>
  
</div>


      </div>
    </main><footer class="site-footer h-card">
  <data class="u-url" href="/"></data>

  <div class="wrapper">

    <h2 class="footer-heading">Just-in-Time learning</h2>

    <div class="footer-col-wrapper">
      <div class="footer-col footer-col-1">
        <ul class="contact-list">
          <li class="p-name">Just-in-Time learning</li></ul>
      </div>

      <div class="footer-col footer-col-2"><ul class="social-media-list">
  <li><a href="https://github.com/ai-mindset"><svg class="svg-icon"><use xlink:href="/assets/minima-social-icons.svg#github"></use></svg> <span class="username">ai-mindset</span></a></li></ul>
</div>

      <div class="footer-col footer-col-3">
        <p>Inquisitive. Learning. Sharing. Simplicity = Reliability</p>
      </div>
    </div>

  </div>

</footer>
</body>

</html>
