<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="3.10.0">Jekyll</generator><link href="http://0.0.0.0:4000/feed.xml" rel="self" type="application/atom+xml" /><link href="http://0.0.0.0:4000/" rel="alternate" type="text/html" /><updated>2025-03-16T07:46:05+00:00</updated><id>http://0.0.0.0:4000/feed.xml</id><title type="html">Just-in-Time learning</title><subtitle>Inquisitive. Learning. Sharing. Simplicity = Reliability</subtitle><entry><title type="html">ü§ñ The State of AI Agents in 2025</title><link href="http://0.0.0.0:4000/navigating-ais-frontier-2025/" rel="alternate" type="text/html" title="ü§ñ The State of AI Agents in 2025" /><published>2025-03-15T00:00:00+00:00</published><updated>2025-03-15T00:00:00+00:00</updated><id>http://0.0.0.0:4000/navigating-ais-frontier-2025</id><content type="html" xml:base="http://0.0.0.0:4000/navigating-ais-frontier-2025/"><![CDATA[<!--more-->

<h2 id="introduction">Introduction</h2>

<p>The AI landscape has evolved at a breathtaking pace over the past few years, with autonomous AI agents being positioned as the next revolutionary frontier. At the 2025 AI Engineer Summit, Grace Isford, a partner at Lux Capital, delivered an <a href="https://www.youtube.com/watch?v=HS5a8VIKsvA">insightful keynote</a> on ‚ÄúThe State of the AI Frontier‚Äù that challenged the prevailing narrative about AI agents. While many industry players proclaim that 2025 marks the ‚Äúperfect storm‚Äù for AI agents, Isford‚Äôs presentation offered a more nuanced view, highlighting both the tremendous progress and the significant challenges that remain. This article summarises the key insights from her keynote, examining the current state of AI agents and the strategies developers can employ to overcome persistent limitations.</p>

<h2 id="the-perfect-storm-for-ai-agents">The Perfect Storm for AI Agents</h2>

<p>The speaker began by acknowledging the remarkable progress in AI over the past two and a half years. The industry has seen exponential advancements since the release of Stable Diffusion in August 2022, with the pace of innovation only accelerating. 2025 has already witnessed several landmark developments:</p>

<ul>
  <li>The announcement of the $500 billion Stargate project collaboration between the U.S. government, OpenAI, SoftBank, and Oracle</li>
  <li>OpenAI‚Äôs o3 model exceeding human performance in the Arc AGI challenge</li>
  <li>DeepSeq‚Äôs R1 model launch causing market disruptions and reaching the top of the App Store</li>
  <li>France‚Äôs new AI initiative announced at the France AI Summit, bringing Europe back into the global AI race</li>
</ul>

<p>These developments, alongside other factors, have created what many call the ‚Äúperfect storm‚Äù for AI agents:</p>

<ol>
  <li>Reasoning models (like OpenAI‚Äôs o1 and o3, DeepSeq‚Äôs R1, and Grok‚Äôs latest offering) now outperform humans in various benchmarks</li>
  <li>Increased test-time compute (more resources allocated to inference rather than just training)</li>
  <li>Engineering and hardware optimisations driving efficiency</li>
  <li>Cheaper inference and hardware costs</li>
  <li>A narrowing gap between open-source and closed-source models</li>
  <li>Massive infrastructure investments from governments and corporations worldwide</li>
</ol>

<h2 id="the-reality-gap-why-ai-agents-arent-quite-working-yet">The Reality Gap: Why AI Agents Aren‚Äôt Quite Working Yet</h2>

<p>Despite this promising landscape, Isford argued that truly autonomous AI agents aren‚Äôt functioning as seamlessly as industry hype suggests. To illustrate this point, she shared a real-world example of trying to use OpenAI‚Äôs operator to book a flight from New York to San Francisco with specific requirements. Despite seemingly straightforward criteria (departure time after 3 PM, avoiding rush hour, specific airlines, budget constraints, seat preferences), the agent failed to deliver a satisfactory result.</p>

<p>The presenter identified five categories of cumulative errors that prevent AI agents from delivering consistent, reliable results:</p>

<ol>
  <li><strong>Decision Errors</strong>: Choosing incorrect facts or overthinking/exaggerating scenarios</li>
  <li><strong>Implementation Errors</strong>: Encountering access issues or integration failures (like CAPTCHA challenges)</li>
  <li><strong>Heuristic Errors</strong>: Applying wrong criteria or missing critical contextual information</li>
  <li><strong>Taste Errors</strong>: Failing to account for personal preferences not explicitly stated</li>
  <li><strong>Perfection Paradox</strong>: User expectations heightened by AI‚Äôs capabilities in some areas lead to frustration when agents perform at merely human speed or make basic errors</li>
</ol>

<p>These errors compound dramatically in complex multi-agent systems with multi-step tasks. Isford presented a compelling visual example showing how even agents with impressive 99% and 95% accuracy rates drop to 60% and 8% reliability respectively after just 50 consecutive steps.</p>

<h2 id="five-strategies-for-building-better-ai-agents">Five Strategies for Building Better AI Agents</h2>

<p>The keynote then shifted to offering concrete strategies for mitigating these challenges and building more effective AI agents:</p>

<h3 id="1-data-curation">1. Data Curation</h3>
<ul>
  <li>Recognise that data is increasingly diverse (text, images, video, audio, sensor data)</li>
  <li>Curate proprietary data, including data generated by the agent itself</li>
  <li>Design ‚Äúdata flywheels‚Äù that automatically improve agent performance through user interactions</li>
  <li>Recycle and adapt to user preferences in real-time</li>
</ul>

<h3 id="2-robust-evaluation-systems">2. Robust Evaluation Systems</h3>
<ul>
  <li>Move beyond evaluations for verifiable domains (math, science) to develop frameworks for subjective assessments</li>
  <li>Collect signals about human preferences</li>
  <li>Build personalised evaluation systems that reflect actual user needs</li>
  <li>Sometimes the best evaluation is direct human testing rather than relying solely on benchmarks</li>
</ul>

<h3 id="3-scaffolding-systems">3. Scaffolding Systems</h3>
<ul>
  <li>Implement safeguards to prevent cascading failures when errors occur</li>
  <li>Build complex compound systems that can work together harmoniously</li>
  <li>Incorporate human intervention at critical junctures</li>
  <li>Develop self-healing agents that can recognise their own mistakes and correct course</li>
</ul>

<h3 id="4-user-experience-as-a-competitive-moat">4. User Experience as a Competitive Moat</h3>
<ul>
  <li>Recognise that UX differentiation is crucial when most applications are using the same foundation models</li>
  <li>Deeply understand user workflows to create elegant human-machine collaboration</li>
  <li>Integrate seamlessly with existing systems to deliver tangible ROI</li>
  <li>Focus on industries with proprietary data sources and specialised workflows (robotics, manufacturing, life sciences)</li>
</ul>

<h3 id="5-multimodal-approaches">5. Multimodal Approaches</h3>
<ul>
  <li>Move beyond basic chatbot interfaces to create more human-like experiences</li>
  <li>Incorporate multiple sensory capabilities (vision, voice, and potentially touch or smell)</li>
  <li>Build personal memory systems that understand users on a deeper level</li>
  <li>Transform inconsistent but visionary products into experiences that exceed expectations through novel interfaces</li>
</ul>

<h2 id="conclusion">Conclusion</h2>

<p>While 2025 has created what appears to be a perfect storm for AI agents with advanced reasoning models, increased compute efficiency, and massive infrastructure investments, the reality is that autonomous AI agents still face significant challenges. The cumulative effect of small errors across decision-making, implementation, heuristics, and user preferences creates substantial reliability issues in complex agent systems.</p>

<p>However, as this keynote emphasised, these challenges are not insurmountable. By focusing on meticulous data curation, developing sophisticated evaluation frameworks, implementing robust scaffolding systems, prioritising distinctive user experiences, and embracing multimodal approaches, developers can build AI agents that deliver on their transformative potential. The lightning strike of truly autonomous, reliable AI agents may not have happened yet, but with these strategies, the industry is moving steadily toward that breakthrough moment.</p>]]></content><author><name></name></author><category term="ai" /><category term="machine-learning" /><category term="llm" /><category term="ai-alignment" /><category term="best-practices" /><category term="evaluation" /><category term="prompt-engineering" /><category term="decision-making" /><summary type="html"><![CDATA[]]></summary></entry><entry><title type="html">üóÑÔ∏è SQLite: The Minimalist Database for AI Engineering</title><link href="http://0.0.0.0:4000/sqlite-minimalist-choice-for-ai-engineering/" rel="alternate" type="text/html" title="üóÑÔ∏è SQLite: The Minimalist Database for AI Engineering" /><published>2025-02-11T00:00:00+00:00</published><updated>2025-02-11T00:00:00+00:00</updated><id>http://0.0.0.0:4000/sqlite-minimalist-choice-for-ai-engineering</id><content type="html" xml:base="http://0.0.0.0:4000/sqlite-minimalist-choice-for-ai-engineering/"><![CDATA[<!--more-->

<h2 id="introduction">Introduction</h2>

<p>In today‚Äôs AI engineering landscape, choosing the right database can feel overwhelming. While specialised solutions like <a href="https://qdrant.tech/">Qdrant</a> (vectors), <a href="https://neo4j.com/">Neo4j</a> (graphs), and <a href="https://www.mongodb.com/">MongoDB</a> (documents) excel in their niches, there‚Äôs a compelling case for <a href="https://www.sqlite.org/index.html">SQLite</a> as a versatile, minimalist solution that comes pre-installed on most systems and supports multiple data structures effectively. Speaking of minimalism, <a href="https://github.com/tconbeer/harlequin">Harlequin</a> (named after a <a href="https://en.wikipedia.org/wiki/Harlequin_duck">sea ü¶Ü</a>) makes data exploration very enjoyable. 
Credit for the SQLite idea goes to <a href="https://bsky.app/profile/simonwillison.net">Simon Willison</a>, a prolific AI researcher among others, who has been posting <a href="https://simonwillison.net/tags/sqlite/">blog articles</a> and <a href="https://til.simonwillison.net/sqlite">TILs</a> (Today I Learned) about it since 2003!</p>

<h2 id="the-power-of-pre-installation">The Power of Pre-installation</h2>

<p>SQLite‚Äôs ubiquity is remarkable. It comes pre-installed on:</p>
<ul>
  <li>macOS</li>
  <li>Most Linux distributions (including Ubuntu, as evidenced by its <a href="https://releases.ubuntu.com/24.10/ubuntu-24.10-desktop-amd64.manifest">manifest</a>)</li>
  <li>Python‚Äôs standard library</li>
  <li>Android devices</li>
  <li>iOS devices</li>
</ul>

<p>This universal availability means you can start developing immediately without additional setup or installation steps.</p>

<h2 id="modern-data-structure-support">Modern Data Structure Support</h2>

<p>Despite its lightweight nature, SQLite handles modern data structures surprisingly well:</p>

<ol>
  <li><strong>Vector Storage</strong><sup id="fnref:1" role="doc-noteref"><a href="#fn:1" class="footnote" rel="footnote">1</a></sup>
    <div class="language-sql highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">CREATE</span> <span class="n">VIRTUAL</span> <span class="k">TABLE</span> <span class="n">vec_items</span> <span class="k">USING</span> <span class="n">vec0</span><span class="p">(</span><span class="n">embedding</span> <span class="nb">float</span><span class="p">[</span><span class="mi">4</span><span class="p">])</span>
</code></pre></div>    </div>
    <div class="language-sql highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">-- vectors can be provided as JSON or in a compact binary format</span>
<span class="k">INSERT</span> <span class="k">INTO</span> <span class="n">vec_items</span><span class="p">(</span><span class="n">rowid</span><span class="p">,</span> <span class="n">embedding</span><span class="p">)</span>
  <span class="k">VALUES</span>
 <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="s1">'[-0.200, 0.250, 0.341, -0.211, 0.645, 0.935, -0.316, -0.924]'</span><span class="p">),</span>
 <span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="s1">'[0.443, -0.501, 0.355, -0.771, 0.707, -0.708, -0.185, 0.362]'</span><span class="p">),</span>
 <span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="s1">'[0.716, -0.927, 0.134, 0.052, -0.669, 0.793, -0.634, -0.162]'</span><span class="p">),</span>
 <span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="s1">'[-0.710, 0.330, 0.656, 0.041, -0.990, 0.726, 0.385, -0.958]'</span><span class="p">);</span>
</code></pre></div>    </div>
    <div class="language-sql highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">-- KNN-style query</span>
<span class="k">SELECT</span>
  <span class="n">rowid</span><span class="p">,</span>
  <span class="n">distance</span>
<span class="k">FROM</span> <span class="n">vec_items</span>
<span class="k">WHERE</span> <span class="n">embedding</span> <span class="k">MATCH</span> <span class="s1">'[0.890, 0.544, 0.825, 0.961, 0.358, 0.0196, 0.521, 0.175]'</span>
<span class="k">ORDER</span> <span class="k">BY</span> <span class="n">distance</span>
<span class="k">LIMIT</span> <span class="mi">3</span>
</code></pre></div>    </div>
  </li>
  <li><strong>Graph Relationships</strong><sup id="fnref:2" role="doc-noteref"><a href="#fn:2" class="footnote" rel="footnote">2</a></sup>
    <div class="language-sql highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">-- Create table `nodes`</span>
<span class="k">CREATE</span> <span class="k">TABLE</span> <span class="n">IF</span> <span class="k">NOT</span> <span class="k">EXISTS</span> <span class="n">nodes</span> <span class="p">(</span>
 <span class="n">id</span> <span class="nb">TEXT</span> <span class="k">PRIMARY</span> <span class="k">KEY</span><span class="p">,</span>
 <span class="n">properties</span> <span class="nb">TEXT</span>
<span class="p">)</span>
</code></pre></div>    </div>
    <div class="language-sql highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">-- Create table `edges`</span>
<span class="k">CREATE</span> <span class="k">TABLE</span> <span class="n">IF</span> <span class="k">NOT</span> <span class="k">EXISTS</span> <span class="n">edges</span> <span class="p">(</span>
 <span class="k">source</span> <span class="nb">TEXT</span><span class="p">,</span>
 <span class="n">target</span> <span class="nb">TEXT</span><span class="p">,</span>
 <span class="n">relationship</span> <span class="nb">TEXT</span><span class="p">,</span>
 <span class="n">weight</span> <span class="nb">REAL</span><span class="p">,</span>
 <span class="k">PRIMARY</span> <span class="k">KEY</span> <span class="p">(</span><span class="k">source</span><span class="p">,</span> <span class="n">target</span><span class="p">,</span> <span class="n">relationship</span><span class="p">),</span>
 <span class="k">FOREIGN</span> <span class="k">KEY</span> <span class="p">(</span><span class="k">source</span><span class="p">)</span> <span class="k">REFERENCES</span> <span class="n">nodes</span><span class="p">(</span><span class="n">id</span><span class="p">),</span>
 <span class="k">FOREIGN</span> <span class="k">KEY</span> <span class="p">(</span><span class="n">target</span><span class="p">)</span> <span class="k">REFERENCES</span> <span class="n">nodes</span><span class="p">(</span><span class="n">id</span><span class="p">)</span>
<span class="p">)</span>
</code></pre></div>    </div>
    <div class="language-sql highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">-- Create indices of the `edges` between `source` and `target`, for improved performance</span>
<span class="k">CREATE</span> <span class="k">INDEX</span> <span class="n">IF</span> <span class="k">NOT</span> <span class="k">EXISTS</span> <span class="n">source_idx</span> <span class="k">ON</span> <span class="n">edges</span><span class="p">(</span><span class="k">source</span><span class="p">)</span>
<span class="k">CREATE</span> <span class="k">INDEX</span> <span class="n">IF</span> <span class="k">NOT</span> <span class="k">EXISTS</span> <span class="n">target_idx</span> <span class="k">ON</span> <span class="n">edges</span><span class="p">(</span><span class="n">target</span><span class="p">)</span>
</code></pre></div>    </div>
    <div class="language-sql highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">-- Count the no. of incoming and outgoing edges per node, known as 'degree centrality' </span>
<span class="k">SELECT</span> <span class="n">id</span><span class="p">,</span>
    <span class="p">(</span><span class="k">SELECT</span> <span class="k">COUNT</span><span class="p">(</span><span class="o">*</span><span class="p">)</span> <span class="k">FROM</span> <span class="n">edges</span> <span class="k">WHERE</span> <span class="k">source</span> <span class="o">=</span> <span class="n">nodes</span><span class="p">.</span><span class="n">id</span><span class="p">)</span> <span class="o">+</span>
    <span class="p">(</span><span class="k">SELECT</span> <span class="k">COUNT</span><span class="p">(</span><span class="o">*</span><span class="p">)</span> <span class="k">FROM</span> <span class="n">edges</span> <span class="k">WHERE</span> <span class="n">target</span> <span class="o">=</span> <span class="n">nodes</span><span class="p">.</span><span class="n">id</span><span class="p">)</span> <span class="k">as</span> <span class="n">degree</span>
<span class="k">FROM</span> <span class="n">nodes</span>
<span class="k">ORDER</span> <span class="k">BY</span> <span class="n">degree</span> <span class="k">DESC</span>
<span class="k">LIMIT</span> <span class="mi">10</span>
</code></pre></div>    </div>
  </li>
  <li><strong>Document Storage</strong>
    <div class="language-sql highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">CREATE</span> <span class="k">TABLE</span> <span class="n">documents</span> <span class="p">(</span>
 <span class="n">id</span> <span class="nb">INTEGER</span> <span class="k">PRIMARY</span> <span class="k">KEY</span><span class="p">,</span>
 <span class="n">content</span> <span class="n">JSON</span><span class="p">,</span>
 <span class="n">metadata</span> <span class="n">JSON</span>
<span class="p">);</span>
</code></pre></div>    </div>
  </li>
</ol>

<h2 id="portability-and-simplicity">Portability and Simplicity</h2>

<p>One of SQLite‚Äôs strongest features is its <a href="https://www.sqlite.org/onefile.html">single-file</a> nature. Your entire database exists in one file that can be:</p>
<ul>
  <li>Backed up with a simple copy operation</li>
  <li>Easily version controlled (for smaller databases)</li>
  <li>Moved between systems effortlessly</li>
  <li>Examined with standard SQLite tools</li>
</ul>

<h2 id="conclusion">Conclusion</h2>

<p>While specialised databases have their place, SQLite offers a compelling combination of features that make it ideal for many AI engineering projects:</p>
<ul>
  <li>Zero configuration</li>
  <li>Pre-installed availability</li>
  <li>Support for multiple data structures</li>
  <li>Single-file portability</li>
  <li>Wide language support, especially in Python and Go</li>
  <li>ACID<sup id="fnref:3" role="doc-noteref"><a href="#fn:3" class="footnote" rel="footnote">3</a></sup> compliance</li>
</ul>

<p><strong>TL;DR</strong>: When you need a lightweight, self-contained database that can handle documents, vectors, and graphs without the complexity of a full database server, SQLite is often an excellent choice.</p>

<hr />
<div class="footnotes" role="doc-endnotes">
  <ol>
    <li id="fn:1" role="doc-endnote">
      <p>Example from <a href="https://alexgarcia.xyz/sqlite-vec/python.html">sqlite-vec with Python</a>¬†<a href="#fnref:1" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
    <li id="fn:2" role="doc-endnote">
      <p>Examples from <a href="https://dev.to/stephenc222/how-to-build-lightweight-graphrag-with-sqlite-53le">How to Build Lightweight GraphRAG with SQLite</a>¬†<a href="#fnref:2" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
    <li id="fn:3" role="doc-endnote">
      <p>Atomicity, Consistency, Isolation, Durability (<a href="https://en.wikipedia.org/wiki/ACID">ACID</a>), per Wikipedia, ‚Äú<em>is a set of properties of database transactions intended to guarantee data validity despite errors, power failures, and other mishaps. In the context of databases, a sequence of database operations that satisfies the ACID properties (which can be perceived as a single logical operation on the data) is called a transaction. For example, a transfer of funds from one bank account to another, even involving multiple changes such as debiting one account and crediting another, is a single transaction.</em>‚Äù¬†<a href="#fnref:3" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
  </ol>
</div>]]></content><author><name></name></author><category term="ai" /><category term="data-modeling" /><category term="data-processing" /><category term="data-science" /><category term="go" /><category term="minimal" /><category term="production" /><category term="python" /><category term="zero-config" /><summary type="html"><![CDATA[]]></summary></entry><entry><title type="html">üí° TIL: To Prepare for AI, Study History‚Äôs Tech Cycles</title><link href="http://0.0.0.0:4000/TIL-prepare-for-ai/" rel="alternate" type="text/html" title="üí° TIL: To Prepare for AI, Study History‚Äôs Tech Cycles" /><published>2025-02-09T00:00:00+00:00</published><updated>2025-02-09T00:00:00+00:00</updated><id>http://0.0.0.0:4000/TIL-prepare-for-ai</id><content type="html" xml:base="http://0.0.0.0:4000/TIL-prepare-for-ai/"><![CDATA[<!--more-->

<h2 id="introduction">Introduction</h2>
<p><a href="https://jeremy.fast.ai/">Jeremy Howard</a> isn‚Äôt just another voice in the AI conversation. As the creator of <a href="https://towardsdatascience.com/understanding-ulmfit-and-elmo-the-shift-towards-transfer-learning-in-nlp-b5d8e2e3f664">ULMFiT</a> (the algorithm that modern LLMs like ChatGPT are based on), founding researcher at <a href="https://course.fast.ai/">fast.ai</a>, and <a href="https://www.answer.ai/">Answer.AI</a>, Howard brings a unique perspective shaped by decades at the forefront of AI development. Recently, when <a href="https://xcancel.com/chrisbarber/status/1888037803566747942">asked about preparing for AI</a>, his response wasn‚Äôt about futuristic predictions or doomsday scenarios. Instead, he offered something more valuable: practical wisdom drawn from historical patterns.</p>

<h2 id="why-this-matters-now">Why This Matters Now</h2>
<p>We‚Äôre at a critical juncture with AI, similar to where we were with the internet in 1990. Just as the internet transformed every aspect of our lives, AI is poised to do the same. The difference? We can learn from history this time. Howard‚Äôs insights are particularly valuable because they come from someone who has not only observed but shaped these technological transitions.</p>

<h2 id="key-insights-on-technology-evolution">Key Insights on Technology Evolution</h2>
<p>Howard emphasises a crucial pattern: technology doesn‚Äôt just grow linearly. Each innovation follows a ‚Äúhockey stick‚Äù growth curve before flattening into a sigmoid.</p>

<center>
    <figure>
        <img src="https://raw.githubusercontent.com/ai-mindset/ai-mindset.github.io/0a6eced3bce4c70b7ba715fe7873d1659ce2e9a9/images/hockey-stick-growth.png" width="80%" height="80%" />
    <figcaption>Hockey stick growth</figcaption>
    </figure>
</center>

<p>More importantly, new ‚Äúhockey sticks‚Äù emerge unexpectedly in different areas. This pattern repeats ‚Äúlike clockwork‚Äù making historical understanding more valuable than future predictions.</p>

<h2 id="practical-preparation-strategy">Practical Preparation Strategy</h2>
<p>Rather than trying to predict AI‚Äôs future, Howard advocates for:</p>
<ul>
  <li>Embracing uncertainty while avoiding both dismissive fear and blind hype</li>
  <li>Taking a counter-cyclical approach: pursuing opportunities others overlook</li>
  <li>Investing months in mastering AI tools, accepting initial poor results as part of the learning process</li>
  <li>Combining AI capabilities with deep domain expertise</li>
  <li>Building practical knowledge through side projects and community engagement</li>
</ul>

<h2 id="the-education-perspective">The Education Perspective</h2>
<p>Howard challenges traditional educational paths, suggesting alternatives:</p>
<ul>
  <li>Self-directed learning through resources like <a href="https://course.fast.ai/">fast.ai</a></li>
  <li>Multiple side hustles to build practical experience</li>
  <li>Community building with like-minded innovators</li>
  <li>Using AI itself to learn technical skills</li>
  <li>Developing both technical and human skills as a generalist</li>
</ul>

<h2 id="conclusion">Conclusion</h2>
<p>The key takeaway isn‚Äôt about predicting AI‚Äôs future -it‚Äôs about preparing for it intelligently. Howard‚Äôs message is: success in the AI era won‚Äôt come from perfect predictions or traditional career paths. Instead, it will come from practical engagement, continuous learning, and the ability to combine domain expertise with AI capabilities. As he puts it, those who master this combination will have ‚Äúsuperpowers‚Äù compared to those who don‚Äôt adapt.<br />
The most valuable insight? Even AI experts can‚Äôt predict AI‚Äôs future reliably. The best strategy is to engage deeply with the technology while maintaining a grounded, practical approach to learning and application. The future belongs to the tinkerers, the experimenters, and those willing to learn from both past and present.</p>]]></content><author><name></name></author><category term="til" /><category term="ai" /><category term="fast-ai" /><category term="llm" /><category term="machine-learning" /><category term="best-practices" /><category term="decision-making" /><category term="evolution" /><summary type="html"><![CDATA[]]></summary></entry><entry><title type="html">üöÄ A Minimal, Pragmatic Approach to Production-Ready AI &amp;amp; ML with Go</title><link href="http://0.0.0.0:4000/go-pragmatic-modern-development/" rel="alternate" type="text/html" title="üöÄ A Minimal, Pragmatic Approach to Production-Ready AI &amp;amp; ML with Go" /><published>2025-01-26T00:00:00+00:00</published><updated>2025-01-26T00:00:00+00:00</updated><id>http://0.0.0.0:4000/go-pragmatic-modern-development</id><content type="html" xml:base="http://0.0.0.0:4000/go-pragmatic-modern-development/"><![CDATA[<!--more-->

<h2 id="introduction">Introduction</h2>

<p>Modern software development often involves navigating complex toolchains, opinionated frameworks, and resource-heavy development environments. Many languages require extensive configuration, multiple runtime dependencies, and introduce significant cognitive overhead through their vast feature sets and multiple approaches to solving the same problem. Node.js, JVM languages, and even Python with its extensive ecosystem can lead to analysis paralysis, code inhomogeneity and team disagreements over tooling and style.<br />
Go offers a refreshing alternative. With a language specification under 50 pages, a consolidated toolchain, and a ‚Äúbatteries included‚Äù approach, it provides a low-cognitive-overhead solution for developers seeking simplicity and productivity. Its zero-config philosophy, coupled with built-in formatting (<code class="language-plaintext highlighter-rouge">go fmt</code>), linting<sup id="fnref:1" role="doc-noteref"><a href="#fn:1" class="footnote" rel="footnote">1</a></sup> (<code class="language-plaintext highlighter-rouge">go vet</code>), and testing tools, promotes code uniformity and reduces team friction over stylistic choices. The sizeable Go community is centralised, using Slack in this case, which serves as a focal point for communication, support, networking, and staying informed about the latest developments.<br />
While Go may lack a REPL as sophisticated as IPython or the Julia interactive environment, this limitation encourages proper Test-Driven Development practices rather than the post-implementation testing often seen in REPL-heavy environments. Tools like <a href="https://github.com/fatih/vim-go">vim-go</a>‚Äôs <code class="language-plaintext highlighter-rouge">:GoRun</code> and Go Playground provide sufficient interactive development capabilities for most use cases.<br />
Below I‚Äôm collecting some thoughts on attractive aspects of Go I‚Äôve discerned so far and how they compare with other languages I‚Äôve considered. The list of Go‚Äôs features is far from complete, for example I‚Äôve not mentioned goroutines among others.</p>

<h2 id="python-vs-go-libraries-comparison">Python vs Go Libraries Comparison</h2>

<table>
  <thead>
    <tr>
      <th>Domain</th>
      <th>Python Library</th>
      <th>Go Equivalent</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>Numerical Computing</td>
      <td><a href="https://github.com/numpy/numpy">NumPy</a></td>
      <td><a href="https://github.com/gonum/gonum">gonum</a></td>
    </tr>
    <tr>
      <td>Data Processing</td>
      <td><a href="https://github.com/pandas-dev/pandas">Pandas</a></td>
      <td><a href="https://github.com/go-gota/gota">gota</a></td>
    </tr>
    <tr>
      <td>Visualisation</td>
      <td><a href="https://github.com/plotly/plotly.py">Plotly</a></td>
      <td><a href="https://github.com/MetalBlueberry/go-plotly">go-plotly</a></td>
    </tr>
    <tr>
      <td>Gradient Boosting</td>
      <td><a href="https://github.com/dmlc/xgboost">XGBoost</a></td>
      <td><a href="https://github.com/Unity-Technologies/go-xgboost">go-xgboost</a></td>
    </tr>
    <tr>
      <td>Machine Learning</td>
      <td><a href="https://github.com/scikit-learn/scikit-learn">Scikit-Learn</a></td>
      <td><a href="https://github.com/sjwhitworth/golearn">golearn</a></td>
    </tr>
    <tr>
      <td>Deep Learning</td>
      <td><a href="https://github.com/tensorflow/tensorflow">TensorFlow</a><br /><a href="https://github.com/pytorch/pytorch">PyTorch</a></td>
      <td><a href="https://github.com/galeone/tfgo">tfgo</a><br /><a href="https://github.com/sugarme/gotch">gotch</a></td>
    </tr>
    <tr>
      <td>LLM Development</td>
      <td><a href="https://github.com/langchain-ai/langchain">LangChain</a></td>
      <td><a href="https://github.com/tmc/langchaingo">langchaingo</a></td>
    </tr>
    <tr>
      <td>Vector Search</td>
      <td><a href="https://github.com/weaviate/weaviate-python-client">Weaviate Client</a></td>
      <td><a href="https://github.com/weaviate/weaviate-python-client">Weaviate Go Client</a></td>
    </tr>
  </tbody>
</table>

<p><em>Update: <a href="https://github.com/Promacanthus/awesome-golang-ai">Awesome Golang.ai</a> is a very nice curated list of AI-related Go libraries worth checking.</em></p>

<h2 id="development-experience">Development Experience</h2>

<p>Go‚Äôs tooling is exceptional. With <a href="https://github.com/fatih/vim-go">vim-go</a> in <a href="https://neovim.io/">Neovim</a>, you get immediate access to formatting, linting, and code navigation. Unlike JVM languages or JavaScript frameworks that may require more complex build configurations, Go projects maintain a simple, predictable structure thanks to <code class="language-plaintext highlighter-rouge">go mod</code>. The <code class="language-plaintext highlighter-rouge">go fmt</code> command -triggered on save by default- enforces consistent code style eliminating debates over formatting and best practices, while <code class="language-plaintext highlighter-rouge">go vet</code> catches common mistakes early.</p>

<h2 id="error-handling-done-right">Error Handling Done Right</h2>

<p>Go‚Äôs approach to error handling initially feels verbose:</p>

<div class="language-go highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">result</span><span class="p">,</span> <span class="n">err</span> <span class="o">:=</span> <span class="n">someFunction</span><span class="p">()</span>
<span class="k">if</span> <span class="n">err</span> <span class="o">!=</span> <span class="no">nil</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">err</span>
<span class="p">}</span>
</code></pre></div></div>

<p>But this explicitness pays dividends. By treating errors as values that must be handled, Go forces developers to think about failure cases upfront. The <code class="language-plaintext highlighter-rouge">defer</code> keyword complements this by ensuring clean-up code runs regardless of errors:</p>

<div class="language-go highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">file</span><span class="p">,</span> <span class="n">err</span> <span class="o">:=</span> <span class="n">os</span><span class="o">.</span><span class="n">Open</span><span class="p">(</span><span class="s">"data.txt"</span><span class="p">)</span>
<span class="k">if</span> <span class="n">err</span> <span class="o">!=</span> <span class="no">nil</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">err</span>
<span class="p">}</span>
<span class="k">defer</span> <span class="n">file</span><span class="o">.</span><span class="n">Close</span><span class="p">()</span>
</code></pre></div></div>

<h2 id="mlai-capabilities">ML/AI Capabilities</h2>

<p>While Go isn‚Äôt the primary choice for ML/AI experimentation, its simplicity and performance make it excellent for production deployments. Its standard library and growing ecosystem provide solid foundations for numerical computing (<a href="https://github.com/gonum/gonum">gonum</a>), data processing (<a href="https://github.com/go-gota/gota">gota</a>), and ML/AI applications (<a href="https://github.com/gorgonia/gorgonia">Gorgonia</a>, <a href="https://github.com/galeone/tfgo">tfgo</a>, <a href="https://github.com/sugarme/gotch">gotch</a>). The language‚Äôs focus on simplicity and performance makes it particularly suitable for model serving and inference workloads.</p>

<h2 id="language-design">Language Design</h2>

<p>Go‚Äôs refreshingly concise specification (under 50 pages) contrasts sharply with other languages. Even the highly promising Zig, a younger language half of Go‚Äôs age, has a 74-page specification despite being positioned as a simpler low-level language.</p>
<figure>
    <img src="https://raw.githubusercontent.com/ai-mindset/ai-mindset.github.io/refs/heads/main/images/Zig%20language%20spec.png" width="80%" height="80%" />
    <figcaption>Zig's language spec</figcaption>
</figure>

<p>Go‚Äôs intentionally limited feature set and single way of solving problems promote maintainable, uniform code that‚Äôs easier to reason about and review, as reflected in its compact language spec.</p>
<figure>
    <img src="https://raw.githubusercontent.com/ai-mindset/ai-mindset.github.io/refs/heads/main/images/Go%20language%20spec.png" width="80%" height="80%" />
    <figcaption>Go's language spec</figcaption>
</figure>

<p>For ML engineers and developers seeking a reliable, low-overhead language that excels at building robust, production-ready applications, Go offers a compelling choice. While it won‚Äôt replace Python for rapid prototyping and research, its simplicity, performance, and consolidated toolchain make it an very compelling addition to any developer‚Äôs toolkit.</p>

<h2 id="conclusion">Conclusion</h2>

<p>To my eyes, Go stands out as a pragmatic choice for modern development through its key strengths:</p>

<ul>
  <li>Minimal cognitive overhead with a 47-page specification</li>
  <li>Zero-config toolchain including formatting, testing, and package management</li>
  <li>Centralised community, providing a single-source of truth</li>
  <li>Enforced error handling and clean resource management via <code class="language-plaintext highlighter-rouge">defer</code></li>
  <li>Growing ML/AI ecosystem comparable to Python‚Äôs established libraries</li>
  <li>Cross-platform compilation and efficient garbage collection</li>
  <li>Single, clear way to solve problems, reducing team friction</li>
  <li>Lightweight development environment compared to JVM, .NET, BEAM or Node.js</li>
</ul>

<p>While Python remains dominant for ML/AI research, prototyping and -frequently- production, Go excels in production environments where code maintainability, performance, and team collaboration are crucial. Its intentionally limited feature set, combined with a comprehensive standard library and maturing ML ecosystem, makes it a very attractive choice for developers seeking simplicity without sacrificing capability.<br />
The language‚Äôs design philosophy strongly aligns with my needs as a Data professional looking to reduce tooling complexity and maintain consistent, reliable codebases. Go‚Äôs lightweight yet rich toolchain allows writing safe, efficient AI and data-oriented code based on simplicity and reliability. This refreshing alternative in today‚Äôs complex development landscape has strongly tempted me to start moving my practice to Go‚Äôs more principled approach.</p>

<hr />
<div class="footnotes" role="doc-endnotes">
  <ol>
    <li id="fn:1" role="doc-endnote">
      <p>Vet is -in essence- a linter, since it helps improve code quality. Quoting Go‚Äôs <a href="https://go.dev/src/cmd/vet/doc.go">vet doc</a> <em>‚ÄúVet examines Go source code and reports suspicious constructs, such as Printf calls whose arguments do not align with the format string. Vet uses heuristics that do not guarantee all reports are genuine problems, but it can find errors not caught by the compilers.‚Äù</em>¬†<a href="#fnref:1" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
  </ol>
</div>]]></content><author><name></name></author><category term="ai" /><category term="go" /><category term="llm" /><category term="minimal" /><category term="machine-learning" /><category term="toolchain" /><category term="zero-config" /><category term="code-quality" /><category term="cross-platform" /><category term="production" /><summary type="html"><![CDATA[]]></summary></entry><entry><title type="html">üîß A 10-Minute Guide to Engineering Machine Learning Systems</title><link href="http://0.0.0.0:4000/ml-best-practices/" rel="alternate" type="text/html" title="üîß A 10-Minute Guide to Engineering Machine Learning Systems" /><published>2025-01-21T00:00:00+00:00</published><updated>2025-01-21T00:00:00+00:00</updated><id>http://0.0.0.0:4000/ml-best-practices</id><content type="html" xml:base="http://0.0.0.0:4000/ml-best-practices/"><![CDATA[<!--more-->

<h2 id="introduction">Introduction</h2>
<p>This is a concise reference guide distilling Martin Zinkevich‚Äôs <a href="https://developers.google.com/machine-learning/guides/rules-of-ml">influential Google article on machine learning best practices</a>. While the original spans 43 detailed rules, this 10-minute summary captures the essential principles for building production ML systems. Whether you‚Äôre starting a new project or reviewing an existing one, this summary can be used as a practical checklist for engineering-focused machine learning.</p>

<h2 id="core-philosophy">Core Philosophy</h2>
<blockquote>
  <p>Do machine learning like the great engineer you are, not like the great machine learning expert you aren‚Äôt.</p>
</blockquote>

<p>Most ML gains come from great features, not algorithms. The basic approach should be:</p>
<ol>
  <li>Ensure solid end-to-end pipeline</li>
  <li>Start with reasonable objective</li>
  <li>Add common-sense features simply</li>
  <li>Maintain pipeline integrity</li>
</ol>

<h2 id="phase-i-before-machine-learning-rules-1-3">Phase I: Before Machine Learning (Rules #1-3)</h2>
<ol>
  <li><strong>Don‚Äôt be afraid to launch without ML</strong>
    <ul>
      <li>Simple heuristics get you 50% of the way</li>
      <li>Launch with heuristics when data is insufficient</li>
      <li>Example: Use install rate for app ranking</li>
    </ul>
  </li>
  <li><strong>First, design and implement metrics</strong>
    <ul>
      <li>Track everything possible in current system</li>
      <li>Get early permission from users</li>
      <li>Design systems with metric instrumentation</li>
      <li>Implement experiment framework</li>
    </ul>
  </li>
  <li><strong>Choose ML over complex heuristics</strong>
    <ul>
      <li>Simple heuristics for launching</li>
      <li>Complex heuristics become unmaintainable</li>
      <li>ML models are easier to maintain long-term</li>
    </ul>
  </li>
</ol>

<h2 id="phase-ii-first-pipeline-rules-4-11">Phase II: First Pipeline (Rules #4-11)</h2>
<ol>
  <li><strong>Keep first model simple, get infrastructure right</strong>
    <ul>
      <li>Focus on data pipeline integrity</li>
      <li>Define clear evaluation metrics</li>
      <li>Plan model integration carefully</li>
    </ul>
  </li>
  <li><strong>Pipeline Health is Critical</strong>
    <ul>
      <li>Test infrastructure independently</li>
      <li>Monitor freshness requirements</li>
      <li>Watch for silent failures</li>
      <li>Give feature columns owners</li>
      <li>Document feature expectations</li>
    </ul>
  </li>
  <li><strong>Starting Your ML System</strong>
    <ul>
      <li>Test getting data into algorithm</li>
      <li>Test getting models out correctly</li>
      <li>Monitor data statistics continuously</li>
      <li>Build alerting system</li>
    </ul>
  </li>
</ol>

<h2 id="your-first-objective-rules-12-15">Your First Objective (Rules #12-15)</h2>
<ol>
  <li><strong>Choose Objectives Wisely</strong>
    <ul>
      <li>Don‚Äôt overthink initial objective choice</li>
      <li>Start with simple, observable metrics</li>
      <li>Use directly observed user behaviours</li>
      <li>Example: clicks, downloads, shares</li>
    </ul>
  </li>
  <li><strong>Model Selection Guidelines</strong>
    <ul>
      <li>Start with interpretable models</li>
      <li>Separate spam filtering from quality ranking</li>
      <li>Use simple linear models initially</li>
      <li>Make debugging easier</li>
    </ul>
  </li>
</ol>

<h2 id="phase-iii-feature-engineering-rules-16-22">Phase III: Feature Engineering (Rules #16-22)</h2>
<ol>
  <li><strong>Plan to launch and iterate</strong>
    <ul>
      <li>Expect regular model updates</li>
      <li>Design for feature flexibility</li>
      <li>Keep infrastructure clean</li>
    </ul>
  </li>
  <li><strong>Feature Engineering Principles</strong>
    <ul>
      <li>Start with directly observed features</li>
      <li>Use cross-product features wisely</li>
      <li>Clean up unused features</li>
      <li>Scale feature complexity with data</li>
    </ul>
  </li>
  <li><strong>Feature Coverage and Quality</strong>
    <ul>
      <li>Features that generalise across contexts</li>
      <li>Monitor feature coverage</li>
      <li>Document feature ownership</li>
      <li>Regular feature clean-up</li>
    </ul>
  </li>
</ol>

<h2 id="human-analysis-rules-23-28">Human Analysis (Rules #23-28)</h2>
<ol>
  <li><strong>Testing and Validation</strong>
    <ul>
      <li>Use crowdsourcing or live experiments</li>
      <li>Measure model deltas explicitly</li>
      <li>Look for error patterns</li>
      <li>Consider long-term effects</li>
    </ul>
  </li>
  <li><strong>Common Pitfalls</strong>
    <ul>
      <li>Engineers aren‚Äôt typical users</li>
      <li>Beware of confirmation bias</li>
      <li>Quantify undesirable behaviours</li>
    </ul>
  </li>
</ol>

<h2 id="training-serving-skew-rules-29-37">Training-Serving Skew (Rules #29-37)</h2>
<ol>
  <li><strong>Prevent Skew</strong>
    <ul>
      <li>Save serving-time features</li>
      <li>Weight sampled data properly</li>
      <li>Reuse code between training/serving</li>
      <li>Test on future data</li>
    </ul>
  </li>
  <li><strong>Monitor Everything</strong>
    <ul>
      <li>Track performance metrics</li>
      <li>Watch data distributions</li>
      <li>Monitor feature coverage</li>
      <li>Check prediction bias</li>
    </ul>
  </li>
</ol>

<h2 id="phase-iv-optimisation-and-complex-models-rules-38-43">Phase IV: Optimisation and Complex Models (Rules #38-43)</h2>
<ol>
  <li><strong>When to Add Complexity</strong>
    <ul>
      <li>After simple approaches plateau</li>
      <li>When objectives are well-aligned</li>
      <li>If maintenance cost justifies gains</li>
    </ul>
  </li>
  <li><strong>Advanced Techniques</strong>
    <ul>
      <li>Keep ensembles simple</li>
      <li>Look for new information sources</li>
      <li>Balance complexity vs. benefits</li>
    </ul>
  </li>
</ol>

<h2 id="final-recommendations">Final Recommendations</h2>
<ol>
  <li><strong>Launch Decisions</strong>
    <ul>
      <li>Consider multiple metrics</li>
      <li>Use proxies for long-term goals</li>
      <li>Balance simple vs. complex</li>
    </ul>
  </li>
  <li><strong>System Evolution</strong>
    <ul>
      <li>Start simple, add complexity gradually</li>
      <li>Monitor consistently</li>
      <li>Keep infrastructure clean</li>
      <li>Document everything</li>
    </ul>
  </li>
</ol>]]></content><author><name></name></author><category term="machine-learning" /><category term="best-practices" /><category term="mlops" /><category term="monitoring" /><category term="production" /><category term="quality-assurance" /><category term="data-science" /><category term="decision-making" /><summary type="html"><![CDATA[]]></summary></entry><entry><title type="html">ü§ñ Understanding AI Agents: Tools, Planning, and Evaluation</title><link href="http://0.0.0.0:4000/agents-chip-huyen/" rel="alternate" type="text/html" title="ü§ñ Understanding AI Agents: Tools, Planning, and Evaluation" /><published>2025-01-14T00:00:00+00:00</published><updated>2025-01-14T00:00:00+00:00</updated><id>http://0.0.0.0:4000/agents-chip-huyen</id><content type="html" xml:base="http://0.0.0.0:4000/agents-chip-huyen/"><![CDATA[<!--more-->

<h2 id="introduction">Introduction</h2>
<p>This article summarises Chip Huyen‚Äôs comprehensive blog post ‚Äú<a href="https://huyenchip.com//2025/01/07/agents.html">Agents</a>‚Äù adapted from her upcoming book AI Engineering (2025). The original piece provides an in-depth examination of intelligent agents, which represent a fundamental concept in AI, defined by Russell and Norvig in their seminal 1995 book <a href="https://en.wikipedia.org/wiki/Artificial_Intelligence:_A_Modern_Approach">Artificial Intelligence: A Modern Approach</a> as anything that can perceive its environment through sensors and act upon it through actuators. Huyen explores how the unprecedented capabilities of foundational models have transformed theoretical possibilities into practical applications, enabling agents to operate in diverse environments -from digital workspaces for coding to physical settings for robotics. These agents can now assist with tasks ranging from website creation to complex negotiations.</p>

<h2 id="understanding-agents-and-their-tools">Understanding Agents and Their Tools</h2>
<p>An agent‚Äôs effectiveness is determined by two key factors: its environment and its tool inventory. The environment defines the scope of possible actions, while tools enable the agent to perceive and act within this environment. Modern agents leverage three distinct categories of tools.<br />
Knowledge augmentation tools, including text retrievers and web browsing capabilities, prevent model staleness by enabling access to current information. However, web browsing tools require careful API selection to protect against unreliable or harmful content. Capability extension tools address inherent model limitations -for instance, providing calculators for precise arithmetic or code interpreters for programming tasks. These interpreters demand robust security measures to prevent code injection attacks.<br />
Write actions represent the most powerful and potentially risky category, enabling agents to modify databases or send emails. These tools are distinguished from read-only actions by their ability to affect the environment directly. The <a href="https://arxiv.org/abs/2304.09842">Chameleon</a> system demonstrated the power of tool augmentation, achieving an 11.37% improvement on ScienceQA (a science question answering task) and 17% on TabMWP (a tabular math problem-solving task) through strategic tool combination.</p>

<center>
    <figure>
           <a href="https://huyenchip.com//2025/01/07/agents.html"><img src="https://huyenchip.com/assets/pics/agents/8-tool-transition.png" width="80%" height="80%" /></a>
        <figcaption>A tool transition tree by Chameleon</figcaption>
    </figure>
</center>

<h2 id="planning-and-execution-strategies">Planning and Execution Strategies</h2>
<p>Effective planning requires balancing granularity and flexibility. While <a href="https://arxiv.org/abs/2302.04761">Toolformer</a> managed with 5 tools and <a href="https://arxiv.org/abs/2304.09842">Chameleon</a> with 13, <a href="https://arxiv.org/abs/2305.15334">Gorilla</a> attempted to handle 1,645 APIs, illustrating the complexity of tool selection. Plans can be expressed either in natural language or specific function calls, each approach offering different advantages in maintainability and precision.<br />
Foundational Model planners require minimal training but need careful prompting, while Reinforcement Learning planners demand extensive training for robustness. Modern planning systems support multiple control flows: sequential, parallel, conditional, and iterative patterns. The <a href="https://arxiv.org/abs/2210.03629">ReAct</a> framework successfully combines reasoning with action,</p>
<center>
    <figure>
        <a href="https://huyenchip.com//2025/01/07/agents.html"><img src="https://huyenchip.com/assets/pics/agents/5-ReAct.png" width="80%" height="80%" /></a>
        <figcaption>ReAct agent</figcaption>
    </figure>
</center>

<p>while <a href="https://arxiv.org/abs/2303.11366">Reflexion</a> separates evaluation and self-reflection for improved performance.</p>
<center>
    <figure>
        <a href="https://huyenchip.com//2025/01/07/agents.html"><img src="https://huyenchip.com/assets/pics/agents/6-reflexion.png" width="80%" height="80%" /></a>
        <figcaption>Reflexion agent</figcaption>
    </figure>
</center>

<h2 id="reflection-and-error-management">Reflection and Error Management</h2>
<p>Continuous reflection and error correction form the backbone of reliable agent systems. The process begins with query validation, continues through plan assessment, and extends to execution monitoring. Chameleon‚Äôs tool transition analysis shows how tools are commonly used together, while Voyager‚Äôs skill manager builds on this by tracking and reusing successful tool combinations.</p>

<h2 id="evaluation-framework">Evaluation Framework</h2>
<p>Agent evaluation requires a comprehensive approach to failure mode analysis. Planning failures might involve invalid tools or incorrect parameters, while tool-specific failures demand targeted analysis. Efficiency metrics must consider not just step count and costs, but also completion time constraints. When comparing AI and human agents, it‚Äôs essential to recognise their different operational patterns -what‚Äôs efficient for one may be inefficient for the other. Working with domain experts helps identify missing tools and validate performance metrics.</p>

<h2 id="conclusion">Conclusion</h2>
<p>Huyen‚Äôs analysis demonstrates that successful AI agents emerge from the careful orchestration of three key elements: strategic tool selection, sophisticated planning mechanisms, and robust evaluation frameworks. While tools dramatically enhance agent capabilities -as evidenced by Chameleon‚Äôs significant performance improvements- their effectiveness depends on thoughtful curation, balancing between Toolformer‚Äôs minimal approach and Gorilla‚Äôs extensive API integration. The integration of planning frameworks like ReAct and Reflexion shows how combining reasoning with action and incorporating systematic reflection can enhance agent performance. However, as an emerging field without established theoretical frameworks, significant challenges remain in tool selection, planning efficiency, and error management. Future developments will focus on agent framework evaluation and memory systems for handling information beyond context limits, while maintaining the delicate balance between capability and control that Huyen emphasises throughout her analysis.</p>]]></content><author><name></name></author><category term="ai" /><category term="llm" /><category term="prompt-engineering" /><category term="system-prompts" /><category term="evaluation" /><category term="best-practices" /><category term="toolchain" /><category term="machine-learning" /><summary type="html"><![CDATA[]]></summary></entry><entry><title type="html">üí° TIL: A Simple Yet Effective Ensemble Technique called Model Soup üç≤</title><link href="http://0.0.0.0:4000/TIL-model-soups/" rel="alternate" type="text/html" title="üí° TIL: A Simple Yet Effective Ensemble Technique called Model Soup üç≤" /><published>2025-01-10T00:00:00+00:00</published><updated>2025-01-10T00:00:00+00:00</updated><id>http://0.0.0.0:4000/TIL-model-soups</id><content type="html" xml:base="http://0.0.0.0:4000/TIL-model-soups/"><![CDATA[<!--more-->

<h2 id="introduction">Introduction</h2>
<p>While most ensemble methods in machine learning combine model predictions, thanks to <a href="https://bsky.app/profile/chrisalbon.com/post/3lfbbixka7c25">Chris Albon</a> I recently learned about an alternative approach called ‚Äú<em>model soups</em>‚Äù that works directly with model parameters. Instead of aggregating outputs, model soups blend the actual weights and biases of neural networks, showing promising results in computer vision and language tasks.</p>

<center>
   <a href="https://bsky.app/profile/chrisalbon.com/post/3lfbbixka7c25"><img src="https://cdn.bsky.app/img/feed_fullsize/plain/did:plc:umpsiyampiq3bpgce7kigydz/bafkreihvr4b4gid7v6y7karhiusawtqfdbhoen2bt6q55pmugyioj3q3gq@jpeg" width="80%" height="80%" /></a>
</center>

<h2 id="main-concept">Main Concept</h2>
<p>Model soups are created by averaging the parameters (weights and biases) of multiple independently trained neural networks that share the same architecture and training setup. For example, if we have three models with weights 2.32, 4.21, and 1.23 for a particular parameter, the ‚Äúsouped‚Äù model would use (2.32 + 4.21 + 1.23) / 3 = 2.587 for that parameter. This process is repeated across all parameters in the network. However, not all parameter combinations lead to improvements -models typically need similar training datasets, optimisation methods, and hyperparameters (like learning rate and batch size) to blend effectively. When done right, parameter-averaged models can outperform both individual networks and traditional prediction-averaging ensembles, while maintaining the inference speed of a single model.</p>

<h2 id="conclusion">Conclusion</h2>
<p>Model soups challenge our intuitions about neural networks by showing that directly averaging weights can produce better results than averaging predictions. While the technique requires careful consideration of training conditions, it provides a computationally efficient way to combine multiple models into a single network, making it particularly valuable for resource-constrained production environments where running multiple models in parallel isn‚Äôt feasible.</p>]]></content><author><name></name></author><category term="neural-network" /><category term="machine-learning" /><category term="performance" /><category term="mlops" /><category term="production" /><category term="evaluation" /><summary type="html"><![CDATA[]]></summary></entry><entry><title type="html">üîç Understanding LLM Interpretability</title><link href="http://0.0.0.0:4000/interpreting-llms/" rel="alternate" type="text/html" title="üîç Understanding LLM Interpretability" /><published>2025-01-09T00:00:00+00:00</published><updated>2025-01-09T00:00:00+00:00</updated><id>http://0.0.0.0:4000/interpreting-llms</id><content type="html" xml:base="http://0.0.0.0:4000/interpreting-llms/"><![CDATA[<!--more-->

<h2 id="introduction">Introduction</h2>
<p>Large Language Models (LLMs) have become increasingly sophisticated, yet understanding their inner workings remains a critical challenge for AI safety and development. This blog post summarises concepts and research presented in <a href="https://www.youtube.com/watch?v=UGO_Ehywuxc">Welch Labs‚Äô video on mechanistic interpretability</a>, examining how LLMs process information and recent advances in making their decision-making processes more transparent.</p>

<h2 id="how-llms-think">How LLMs Think</h2>
<p>LLMs process text through a sophisticated pipeline:</p>
<ol>
  <li>Text is converted into tokens and mapped to vectors</li>
  <li>These vectors flow through multiple layers via ‚Äú<em>residual streams</em>‚Äù</li>
  <li>Each layer transforms the information through attention mechanisms</li>
  <li>Final outputs emerge from probability distributions across possible tokens</li>
</ol>

<p>This process, while mathematically precise, creates a black box of neural connections that resist simple interpretation.</p>

<h2 id="the-challenge-of-model-transparency">The Challenge of Model Transparency</h2>
<p><a href="https://ai.google.dev/gemma">Google Gemma</a> models‚Äô analysis of the sentence ‚Äú<em>the reliability of Wikipedia is very</em>‚Äù demonstrates this complexity. The model assigns varying probabilities to different completions:</p>
<ul>
  <li>‚Äú<em>important</em>‚Äù (20.21%)</li>
  <li>‚Äú<em>high</em>‚Äù (11.16%)</li>
  <li>‚Äú<em>questionable</em>‚Äù (9.48%)</li>
</ul>

<p>These probabilities emerge from intricate interactions between neurons, leading to a phenomenon called <em>superposition</em><sup id="fnref:1" role="doc-noteref"><a href="#fn:1" class="footnote" rel="footnote">1</a></sup>.</p>

<h2 id="superposition-and-its-solution">Superposition and Its Solution</h2>
<p>Unlike vision models where neurons correspond to specific concepts, LLMs exhibit <a href="https://arxiv.org/abs/2210.01892">polysemanticity</a> -individual neurons respond to multiple, unrelated concepts. This occurs because LLMs encode more concepts than available neurons by using specific neuron combinations.</p>

<p>This complexity necessitated the development of <a href="/sparse-autoencoders/">sparse autoencoders</a>, which:</p>
<ol>
  <li>Map complex neuron combinations to specific concepts</li>
  <li>Extract interpretable features from LLMs</li>
  <li>Enable direct manipulation of model behaviour</li>
</ol>

<h2 id="practical-implications">Practical Implications</h2>
<p>Understanding LLM internals has crucial implications:</p>
<ul>
  <li><strong>AI Safety</strong>: Better control over model behaviours and outputs</li>
  <li><strong>Development</strong>: More targeted improvements in model capabilities</li>
  <li><strong>Deployment</strong>: Enhanced ability to predict and prevent unwanted behaviours</li>
  <li><strong>Trust</strong>: Greater transparency in AI decision-making processes</li>
</ul>

<h2 id="conclusions">Conclusions</h2>
<p>While tools like sparse autoencoders have provided unprecedented insights into model behaviour, they‚Äôve also revealed the vast complexity of LLM internal mechanisms -the ‚Äúdark matter‚Äù of AI. As these models become more integral to society, advancing our ability to interpret and control them becomes increasingly critical for responsible AI development.<br />
This improved understanding represents not just academic progress, but a crucial step toward safer, more reliable AI systems.</p>

<hr />
<div class="footnotes" role="doc-endnotes">
  <ol>
    <li id="fn:1" role="doc-endnote">
      <p>superposition in the context of neural networks is the ability of a single neuron to represent multiple features simultaneously.  <a href="https://hdl.handle.net/1721.1/157073">https://hdl.handle.net/1721.1/157073</a>¬†<a href="#fnref:1" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
  </ol>
</div>]]></content><author><name></name></author><category term="ai" /><category term="llm" /><category term="machine-learning" /><category term="neural-network" /><category term="model-governance" /><category term="ai-alignment" /><category term="interpretability" /><summary type="html"><![CDATA[]]></summary></entry><entry><title type="html">üìê Sparse Autoencoders: A Technical Overview</title><link href="http://0.0.0.0:4000/sparse-autoencoders/" rel="alternate" type="text/html" title="üìê Sparse Autoencoders: A Technical Overview" /><published>2025-01-09T00:00:00+00:00</published><updated>2025-01-09T00:00:00+00:00</updated><id>http://0.0.0.0:4000/sparse-autoencoders</id><content type="html" xml:base="http://0.0.0.0:4000/sparse-autoencoders/"><![CDATA[<!--more-->

<h2 id="introduction">Introduction</h2>
<p>Supervised learning has achieved remarkable successes in areas ranging from computer vision to genomics. However, as Andrew Ng points out in his <a href="https://web.stanford.edu/class/cs294a/sparseAutoencoder.pdf">CS294A lecture notes</a>, it faces a fundamental limitation: the need for manually engineered features. While researchers have spent years crafting specialised features for vision, audio, and text processing, this approach neither scales nor generalises well.
Sparse autoencoders offer an elegant solution to this challenge by automatically learning features from unlabelled data. These neural networks are distinguished by two key characteristics:</p>
<ol>
  <li>They attempt to reconstruct their input, forcing them to capture essential data patterns</li>
  <li>They employ a sparsity constraint that mimics biological neural systems, where neurons fire infrequently and selectively</li>
</ol>

<p>While simple implementations may not outperform hand-engineered features in specific domains like computer vision, their strength lies in their generality and biological plausibility. The sparse coding principle has proven effective across diverse domains including audio, text, and visual processing.<br />
The mathematical framework combines reconstruction error, regularisation, and sparsity penalties to learn efficient, interpretable representations. This approach not only advances machine learning capabilities but also provides insights into how biological neural networks might learn and process information.
This overview examines the mathematical foundations, practical implementation, and emergent properties of sparse autoencoders, following the framework presented in Stanford‚Äôs CS294A course notes.</p>

<h2 id="sparse-autoencoders">Sparse Autoencoders</h2>
<p>An autoencoder is a neural network that learns to reconstruct its input. In a sparse autoencoder, we add a critical biological constraint: neurons should be ‚Äúinactive‚Äù most of the time, mimicking how biological neurons exhibit low average firing rates.<br />
The basic architecture is:</p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Input (x) -&gt; Hidden Layer (sparse activation) -&gt; Output (xÃÇ)
</code></pre></div></div>
<p>Where:</p>
<ul>
  <li>Input and output dimensions are equal $(x, \hat{x} \in \R^n)$</li>
  <li>Hidden layer learns a sparse representation</li>
  <li>Network uses sigmoid activation: $f(z) = \frac{1}{1+e^{-z}}$</li>
</ul>

<h2 id="mathematical-framework">Mathematical Framework</h2>

<ol>
  <li>
    <p><strong>Base Cost Function</strong> (single training example):</p>

\[J(W,b; x,y) = \frac{1}{2}||h_{W,b}(x) - y||^2\]

    <p>For a single training example:<br />
     - Measures reconstruction error between network output $h_{W,b}(x)$ and target $y$<br />
     - For autoencoders: $y = x$ (we reconstruct the input)<br />
     - $\frac{1}{2}$ factor simplifies gradient computations<br />
     - Squared L2 norm penalises larger reconstruction errors quadratically</p>
  </li>
  <li>
    <p><strong>Full Cost Function with Weight Decay</strong>:</p>

    <p>The cost function $J(W,b)$ combines the average reconstruction error<br />
 $\frac{1}{m}\sum_{i=1}^m \frac{1}{2}||h_{W,b}(x^{(i)}) - x^{(i)}||^2$</p>

    <p>with the weight decay regularisation, to prevent overfitting by penalising large weights:<br />
 $\frac{\lambda}{2}\sum_{l=1}^{n_l-1}\sum_{i=1}^{s_l}\sum_{j=1}^{s_{l+1}}(W_{ji}^{(l)})^2$</p>

\[J(W,b) = \left[\frac{1}{m}\sum_{i=1}^m \frac{1}{2}||h_{W,b}(x^{(i)}) - y^{(i)}||^2\right] + \frac{\lambda}{2}\sum_{l=1}^{n_l-1}\sum_{i=1}^{s_l}\sum_{j=1}^{s_{l+1}}(W_{ji}^{(l)})^2\]

    <p>Key points:</p>
    <ul>
      <li>For autoencoders, output $y^{(i)}$ equals input $x^{(i)}$</li>
      <li>Weight decay applies only to weights $W$, not biases $b$</li>
      <li>$\lambda$ balances reconstruction accuracy vs. weight magnitude</li>
      <li>The $\frac{1}{2}$ factor simplifies derivative calculations in backpropagation</li>
      <li>This regularisation is distinct from the sparsity constraint (KL divergence term)</li>
    </ul>
  </li>
  <li>
    <p><strong>Sparsity Measurement</strong>:</p>

    <p>The average activation $\hat{\rho}_j$ measures how frequently hidden unit $j$ fires across the training set:</p>

\[\hat{\rho}_j = \frac{1}{m}\sum_{i=1}^m[a_j^{(2)}(x^{(i)})]\]

    <p>Key points:</p>
    <ul>
      <li>$a_j^{(2)}(x^{(i)})$ is hidden unit $j$‚Äôs activation for input $x^{(i)}$</li>
      <li>With sigmoid activation:
        <ul>
          <li>Values near 1 mean ‚Äúactive‚Äù or ‚Äúfiring‚Äù</li>
          <li>Values near 0 mean ‚Äúinactive‚Äù</li>
        </ul>
      </li>
      <li>We constrain $\hat{\rho}_j \approx \rho$ where $\rho$ is small (typically 0.05)</li>
      <li>This enforces selective firing: each neuron responds strongly to specific input patterns</li>
    </ul>
  </li>
  <li>
    <p><strong>Sparsity Penalty</strong> (using <a href="https://en.wikipedia.org/wiki/Kullback%E2%80%93Leibler_divergence">KL divergence</a>):</p>

    <p>The sparsity penalty uses KL divergence to enforce \(\hat{\rho}_j \approx \rho\):</p>

\[\sum_{j=1}^{s_2}\rho\log\frac{\rho}{\hat{\rho}_j} + (1-\rho)\log\frac{1-\rho}{1-\hat{\rho}_j}\]

    <p>Properties of this penalty:</p>
    <ul>
      <li>Minimised (zero) when $\hat{\rho}_j = \rho$</li>
      <li>Monotonically increases as $\hat{\rho}_j$ deviates from $\rho$</li>
      <li>Becomes infinite as $\hat{\rho}_j$ approaches 0 or 1</li>
    </ul>
  </li>
  <li>
    <p><strong>Final Cost Function</strong>:</p>

\[J_{sparse}(W,b) = J(W,b) + \beta\sum_{j=1}^{s_2}KL(\rho||\hat{\rho}_j)\]

    <p>Components:</p>
    <ul>
      <li>$J(W,b)$: Standard autoencoder cost (reconstruction error + weight decay)</li>
      <li>Sparsity term: KL divergence penalty summed over $s_2$ hidden units</li>
    </ul>

    <p>$\beta$ controls:</p>
    <ul>
      <li>Balance between accurate reconstruction and sparse representation</li>
      <li>Strength of sparsity enforcement</li>
      <li>Higher $\beta$ ‚Üí stronger sparsity constraint</li>
    </ul>

    <p>This formulation naturally penalises both over- and under-activation of hidden units relative to target sparsity $\rho$.</p>
  </li>
</ol>

<h2 id="training-process">Training Process</h2>

<p>The key modification to standard backpropagation occurs in the hidden layer:</p>

\[\delta_i^{(2)} = \left(\sum_{j=1}^{s_3}W_{ji}^{(3)}\delta_j^{(3)}\right)f'(s_i^{(2)}) + \beta\left(-\frac{\rho}{\hat{\rho}_i} + \frac{1-\rho}{1-\hat{\rho}_i}\right)\]

<p>Where:</p>
<ul>
  <li>First term: Standard backpropagation gradient through the network</li>
  <li>Second term: Gradient of KL-divergence sparsity penalty</li>
  <li>$s_i^{(2)}$ is weighted input sum to hidden unit $i$</li>
  <li>$\hat{\rho}_i$ must be pre-computed using full training set</li>
</ul>

<p>This modification ensures gradient descent optimises both reconstruction accuracy and sparsity.</p>

<h2 id="practical-guidelines">Practical Guidelines</h2>

<ul>
  <li>$\rho$ ‚âà 0.05 (5% target activation rate)</li>
  <li>$\beta$ controls sparsity penalty strength</li>
  <li>Initialise weights randomly near zero</li>
  <li>Must compute forward pass on all examples first to calculate $\hat{\rho}$</li>
</ul>

<h2 id="results">Results</h2>
<p>When trained on images, the network naturally learns edge detectors at different orientations, similar to what is found in the visual cortex. This emergence of biologically plausible features validates the sparsity approach.</p>

<h2 id="conclusion">Conclusion</h2>

<p>Sparse autoencoders represent a mathematically principled approach to unsupervised feature learning, combining biological inspiration with rigorous optimisation techniques. Their key innovation lies in the sparsity constraint, implemented through KL divergence, which forces hidden units to develop specialised, interpretable features.</p>

<p>The mathematical framework achieves this through three key components:</p>
<ol>
  <li>A reconstruction cost that ensures faithful data representation</li>
  <li>A weight decay term that prevents overfitting</li>
  <li>A sparsity penalty that enforces selective neural activation</li>
</ol>

<p>This formulation has proven successful in practice, typically leading to:</p>
<ul>
  <li>Edge and feature detectors emerging naturally from visual data</li>
  <li>Interpretable representations comparable to biological neural coding</li>
  <li>Robust feature learning even with <a href="https://en.wikipedia.org/wiki/Overcompleteness">overcomplete</a> hidden layers</li>
</ul>

<p>The practical value of sparse autoencoders extends beyond their theoretical elegance -they provide a foundation for understanding how neural networks can learn meaningful data representations without supervision. Their success in learning biologically plausible features validates both their design principles and their potential for advanced machine learning applications. Their main limitation lies in hyperparameter sensitivity, particularly to the sparsity target œÅ and weight Œ≤, requiring careful tuning for optimal performance.</p>]]></content><author><name></name></author><category term="ai" /><category term="llm" /><category term="neural-network" /><category term="machine-learning" /><category term="data-science" /><category term="linear-algebra" /><category term="statistics" /><category term="evaluation" /><category term="interpretability" /><category term="modelling-mindsets" /><category term="design-principles" /><category term="best-practices" /><category term="data-processing" /><summary type="html"><![CDATA[]]></summary></entry><entry><title type="html">üí° TIL: How Different Societies View and Value Choice</title><link href="http://0.0.0.0:4000/TIL-the-art-of-choice/" rel="alternate" type="text/html" title="üí° TIL: How Different Societies View and Value Choice" /><published>2025-01-08T00:00:00+00:00</published><updated>2025-01-08T00:00:00+00:00</updated><id>http://0.0.0.0:4000/TIL-the-art-of-choice</id><content type="html" xml:base="http://0.0.0.0:4000/TIL-the-art-of-choice/"><![CDATA[<!--more-->

<h2 id="introduction">Introduction</h2>
<p>Today I revisited a talk on <a href="https://www.youtube.com/watch?v=lDq9-QxvsNU">the art of choosing</a> by Sheena Iyengar. A humourous and informative presentation, it reminded me that our assumptions about choice ‚Äìas studied by Prof. Iyengar through research spanning American, European and Asian populations‚Äì reveals fascinating cultural differences in how we perceive and respond to choice. Her research reveals some eye-opening insights that I‚Äôll briefly summarise below.</p>

<h2 id="perceiving-choice">Perceiving Choice</h2>
<p>First, while Americans believe individual choice is sacred (think ‚Äúhave it your way‚Äù), research shows this isn‚Äôt universal. When studying children solving puzzles, Asian-American children actually performed better when their mothers chose for them, while Anglo-American children did better choosing for themselves. This reveals how deeply cultural context shapes not just our preferences, but the actual effectiveness of our choices.</p>

<p>Second, remember how overwhelming it feels staring at 50 different breakfast cereals? Turns out, people from post-communist countries often saw seven different sodas as just one choice: ‚Äúsoda or no soda.‚Äù This isn‚Äôt because they‚Äôre less sophisticated, it‚Äôs because the ability to spot tiny differences between products is a learned skill -not a natural one.</p>

<p>Most striking was the research on medical decisions. When comparing American and French parents making end-of-life decisions for infants, American parents had more negative emotions and guilt despite insisting on having the choice, while French parents, whose doctors made the decisions, coped better. This challenges the core American belief that having choice is always better.</p>

<p>Concluding with a personal story, Prof. Iyengar -who is blind- shared how she once brought two ‚Äúclearly different‚Äù shades of pink nail polish to her lab. When she removed the labels, half the participants couldn‚Äôt tell them apart. Those who could, chose differently when the labels were present versus absent, showing how marketing narratives shape what we think we‚Äôre choosing.</p>

<h2 id="conclusions">Conclusions</h2>
<p>The TL;DR is: Through cross-cultural research, Prof. Iyengar shows that how we understand and value choice varies dramatically across cultures. Sometimes, having fewer choices or letting others choose for us might actually lead to better outcomes. <br />
As a technologist, inundated with a very wide choice of tools that often offer similar results, I have made the conscious decision to reduce my tooling footprint to the minimum viable toolstack possible. I‚Äôm happy to let more knowledgeable professionals choose, with <em>adequate justification</em>, tools for my line of work but I do disagree with the zealotry that‚Äôs occasionally observed in tech and complemented by big egos.</p>]]></content><author><name></name></author><category term="til" /><category term="decision-making" /><category term="best-practices" /><category term="evaluation" /><category term="statistics" /><category term="design-principles" /><category term="modelling-mindsets" /><summary type="html"><![CDATA[]]></summary></entry></feed>